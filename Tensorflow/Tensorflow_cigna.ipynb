{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_cigna.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fyyn7W5nxFFQ",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow 初探"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdtL-aFbg_Rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOqxIl0Qhcrf",
        "colab_type": "code",
        "outputId": "abeb6a75-62b3-4ae8-e9be-703759748bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGbQ1u0diGze",
        "colab_type": "code",
        "outputId": "80245a1f-36c1-4368-a301-f238661a251e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IG9RXSNjqA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NN(m1,m2,w1,w2,b):\n",
        "  z = m1 * w1 + m2 * w2 + b\n",
        "  return sigmoid(z)\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJFE7oiniHYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlYL6Mu-iAWo",
        "colab_type": "code",
        "outputId": "69a274d2-a775-428d-f87a-960e1c276d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w1=np.random.randn()\n",
        "w2=np.random.randn()\n",
        "b=np.random.randn()\n",
        "phrases = [\"看起來像\",\"我猜是\",\"我想是\",\"可能是\",\"看起來像是\"]\n",
        "data = [[3,1.5,1],[2,1,0],[4,1.5,1],[3.5,5,0],[2.0,5,1]]\n",
        "rand_data = data[np.random.randint(len(data))]\n",
        "m1 = rand_data[0]\n",
        "m2 = rand_data[1]\n",
        "prediction = NN(m1,m2,w1,w2,b)\n",
        "prediction_text = ['藍色','紅色'][int(np.round(prediction))]\n",
        "phrase = np.random.choice(phrases) + \"\" + prediction_text\n",
        "o = '這個' + phrase + '真的是' + ['藍色','紅色'][rand_data[2]]\n",
        "o"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'這個看起來像藍色真的是紅色'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep5fVitJhczY",
        "colab_type": "code",
        "outputId": "d50d05ea-9a46-4ab2-9c23-265ba18aceb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "#Example NN\n",
        "n_features = 3\n",
        "n_dense_neurons = 3\n",
        "tf.set_random_seed(101)\n",
        "\n",
        "x = tf.placeholder(tf.float32, (None, n_features))\n",
        "b = tf.Variable(tf.zeros([n_dense_neurons]))\n",
        "W = tf.Variable(tf.random_normal([n_features,n_dense_neurons]))\n",
        "xW = tf.matmul(x,W)\n",
        "z = tf.add(xW, b)\n",
        "a = tf.sigmoid(z)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  layer_out = sess.run(a,feed_dict = {x : np.random.random([5,n_features])})\n",
        "print(layer_out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "[[0.37180263 0.4848752  0.40013963]\n",
            " [0.37374812 0.5469098  0.48332396]\n",
            " [0.29870242 0.51684254 0.45256433]\n",
            " [0.3235687  0.45716134 0.43859345]\n",
            " [0.43333548 0.42000324 0.42359108]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn2ONXskhc17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.constant([[1,0,1,0],[1,0,1,1],[0,1,0,1]], dtype=tf.float32)\n",
        "y = tf.constant([[1],[1],[0]],dtype=tf.float32)\n",
        "def sigmoid(x):\n",
        "  return 1/(1+tf.exp(-x))\n",
        "def derivatives_sigmoid(x):\n",
        "    return x * (1 - x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeJMmK1xqDpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 1000\n",
        "lr = 0.1\n",
        "inputlayer_neurons = X.shape[1]\n",
        "hiddenlayer_neurons = 10\n",
        "output_neurons = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y26cV8p2qDq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wh = tf.random_normal(shape=[int(inputlayer_neurons),int(hiddenlayer_neurons)],\n",
        "                      mean=0.0,stddev=1.0,\n",
        "                      dtype=tf.float32,seed=None,name=None)\n",
        "bh =  tf.random_normal(shape=[1,int(hiddenlayer_neurons)],\n",
        "                      mean=0.0,stddev=1.0,\n",
        "                      dtype=tf.float32,seed=None,name=None)\n",
        "wout =  tf.random_normal(shape=[int(hiddenlayer_neurons),int(output_neurons)],\n",
        "                      mean=0.0,stddev=1.0,\n",
        "                      dtype=tf.float32,seed=None,name=None)\n",
        "bout =  tf.random_normal(shape=[1,int(output_neurons)],\n",
        "                      mean=0.0,stddev=1.0,\n",
        "                      dtype=tf.float32,seed=None,name=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NATrfKTxqDt8",
        "colab_type": "code",
        "outputId": "f908ee1a-a22e-479c-db32-2c2cd1f7d303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "for i in range(epoch):\n",
        "  hidden_layer_input1 = tf.matmul(X, wh)\n",
        "  hidden_layer_input = hidden_layer_input1 + bh\n",
        "  hidden_layer_activations = sigmoid(hidden_layer_input)\n",
        "  output_layer_input1 = tf.matmul(hidden_layer_activations, wout)\n",
        "  output_layer_input = output_layer_input1 + bout\n",
        "  output = sigmoid(output_layer_input)\n",
        "  \n",
        "  E= y-output\n",
        "  back_output_layer = derivatives_sigmoid(output)\n",
        "  back_hidden_layer = derivatives_sigmoid(hidden_layer_activations)\n",
        "  d_output = E * back_output_layer\n",
        "  Error_at_hidden_layer = tf.matmul(d_output, tf.transpose(wout))\n",
        "  d_hiddenlayer = Error_at_hidden_layer * back_hidden_layer\n",
        "  wout += tf.matmul(tf.transpose(hidden_layer_activations), d_output) * lr \n",
        "  bout += tf.reduce_sum(d_output) * lr\n",
        "  wh += tf.matmul(tf.transpose(X), d_hiddenlayer) * lr\n",
        "  bh += tf.reduce_sum(d_output)*lr\n",
        "  \n",
        "sess = tf.Session()\n",
        "print('Actual :\\n', sess.run(y), '\\n')\n",
        "print('Predicted :\\n', sess.run(output), '\\n')\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual :\n",
            " [[1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "\n",
            "Predicted :\n",
            " [[0.9697147 ]\n",
            " [0.92694074]\n",
            " [0.09504487]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFdHofKzqDw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjam3_iWqDy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_iris()\n",
        "x_train, x_test, y_train, y_test= train_test_split(data.data, data.target, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAawHwqlqD03",
        "colab_type": "code",
        "outputId": "a6bd2e39-15c7-476b-c746-8062fdd2029e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(500, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "adam = tf.keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#model.fit(x_train, y_train, epochs=50)\n",
        "history = model.fit(x_train, y_train, epochs=100, validation_split=0.3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0821 02:25:12.908116 140339020412800 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 73 samples, validate on 32 samples\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - 1s 11ms/sample - loss: 2.6117 - acc: 0.0685 - val_loss: 2.0546 - val_acc: 0.3750\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - 0s 178us/sample - loss: 1.9601 - acc: 0.3288 - val_loss: 1.5441 - val_acc: 0.5625\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - 0s 164us/sample - loss: 1.4492 - acc: 0.5342 - val_loss: 1.2325 - val_acc: 0.5625\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - 0s 140us/sample - loss: 1.2534 - acc: 0.5068 - val_loss: 1.0361 - val_acc: 0.5938\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - 0s 161us/sample - loss: 1.0224 - acc: 0.6301 - val_loss: 0.9142 - val_acc: 0.5938\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - 0s 155us/sample - loss: 0.9114 - acc: 0.7123 - val_loss: 0.8556 - val_acc: 0.8438\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - 0s 161us/sample - loss: 0.8759 - acc: 0.6575 - val_loss: 0.8088 - val_acc: 0.8438\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - 0s 179us/sample - loss: 0.8123 - acc: 0.7397 - val_loss: 0.7663 - val_acc: 0.8750\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - 0s 153us/sample - loss: 0.7744 - acc: 0.6986 - val_loss: 0.7425 - val_acc: 0.5938\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - 0s 163us/sample - loss: 0.7804 - acc: 0.6712 - val_loss: 0.7188 - val_acc: 0.5938\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - 0s 166us/sample - loss: 0.7180 - acc: 0.6712 - val_loss: 0.6905 - val_acc: 0.6250\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - 0s 156us/sample - loss: 0.6345 - acc: 0.7534 - val_loss: 0.6642 - val_acc: 0.6250\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - 0s 161us/sample - loss: 0.6305 - acc: 0.7671 - val_loss: 0.6400 - val_acc: 0.9062\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - 0s 150us/sample - loss: 0.6276 - acc: 0.7808 - val_loss: 0.6214 - val_acc: 0.9375\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - 0s 151us/sample - loss: 0.6023 - acc: 0.7260 - val_loss: 0.6055 - val_acc: 0.7812\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - 0s 170us/sample - loss: 0.5840 - acc: 0.7260 - val_loss: 0.5921 - val_acc: 0.6562\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - 0s 196us/sample - loss: 0.5487 - acc: 0.7671 - val_loss: 0.5735 - val_acc: 0.7500\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - 0s 191us/sample - loss: 0.5721 - acc: 0.7260 - val_loss: 0.5544 - val_acc: 0.9375\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - 0s 161us/sample - loss: 0.5424 - acc: 0.8219 - val_loss: 0.5427 - val_acc: 0.9688\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - 0s 157us/sample - loss: 0.5002 - acc: 0.8493 - val_loss: 0.5323 - val_acc: 1.0000\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - 0s 169us/sample - loss: 0.5051 - acc: 0.8356 - val_loss: 0.5280 - val_acc: 0.7812\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - 0s 163us/sample - loss: 0.4971 - acc: 0.7808 - val_loss: 0.5242 - val_acc: 0.7500\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - 0s 157us/sample - loss: 0.5017 - acc: 0.7808 - val_loss: 0.5100 - val_acc: 0.8438\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - 0s 162us/sample - loss: 0.4870 - acc: 0.7671 - val_loss: 0.4968 - val_acc: 0.9375\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - 0s 146us/sample - loss: 0.4634 - acc: 0.8493 - val_loss: 0.4853 - val_acc: 0.9375\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - 0s 158us/sample - loss: 0.4618 - acc: 0.8219 - val_loss: 0.4736 - val_acc: 1.0000\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - 0s 156us/sample - loss: 0.4571 - acc: 0.8356 - val_loss: 0.4652 - val_acc: 0.9375\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - 0s 173us/sample - loss: 0.4525 - acc: 0.8356 - val_loss: 0.4576 - val_acc: 0.9062\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - 0s 151us/sample - loss: 0.4319 - acc: 0.8219 - val_loss: 0.4458 - val_acc: 1.0000\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - 0s 174us/sample - loss: 0.4303 - acc: 0.8219 - val_loss: 0.4380 - val_acc: 1.0000\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - 0s 177us/sample - loss: 0.4234 - acc: 0.8356 - val_loss: 0.4314 - val_acc: 1.0000\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - 0s 190us/sample - loss: 0.4198 - acc: 0.8904 - val_loss: 0.4243 - val_acc: 1.0000\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - 0s 181us/sample - loss: 0.4069 - acc: 0.8767 - val_loss: 0.4179 - val_acc: 1.0000\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - 0s 190us/sample - loss: 0.4284 - acc: 0.8356 - val_loss: 0.4122 - val_acc: 1.0000\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - 0s 163us/sample - loss: 0.4211 - acc: 0.8219 - val_loss: 0.4071 - val_acc: 1.0000\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - 0s 228us/sample - loss: 0.4120 - acc: 0.8219 - val_loss: 0.4003 - val_acc: 1.0000\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - 0s 154us/sample - loss: 0.3946 - acc: 0.9041 - val_loss: 0.3982 - val_acc: 0.9688\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - 0s 156us/sample - loss: 0.3790 - acc: 0.9041 - val_loss: 0.3936 - val_acc: 0.9688\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - 0s 211us/sample - loss: 0.3709 - acc: 0.8767 - val_loss: 0.3827 - val_acc: 0.9688\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - 0s 205us/sample - loss: 0.3744 - acc: 0.9041 - val_loss: 0.3752 - val_acc: 1.0000\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - 0s 165us/sample - loss: 0.3630 - acc: 0.9178 - val_loss: 0.3709 - val_acc: 1.0000\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - 0s 157us/sample - loss: 0.3296 - acc: 0.9178 - val_loss: 0.3663 - val_acc: 1.0000\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - 0s 142us/sample - loss: 0.3976 - acc: 0.7945 - val_loss: 0.3593 - val_acc: 1.0000\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - 0s 147us/sample - loss: 0.3305 - acc: 0.9315 - val_loss: 0.3601 - val_acc: 0.9688\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - 0s 164us/sample - loss: 0.3636 - acc: 0.8767 - val_loss: 0.3758 - val_acc: 0.9375\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - 0s 173us/sample - loss: 0.3523 - acc: 0.9041 - val_loss: 0.3557 - val_acc: 0.9688\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - 0s 149us/sample - loss: 0.3783 - acc: 0.8219 - val_loss: 0.3394 - val_acc: 1.0000\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - 0s 173us/sample - loss: 0.3233 - acc: 0.9041 - val_loss: 0.3382 - val_acc: 1.0000\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - 0s 159us/sample - loss: 0.3427 - acc: 0.8630 - val_loss: 0.3505 - val_acc: 0.9062\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - 0s 154us/sample - loss: 0.3630 - acc: 0.8356 - val_loss: 0.3337 - val_acc: 0.9375\n",
            "Epoch 51/100\n",
            "73/73 [==============================] - 0s 174us/sample - loss: 0.3330 - acc: 0.8493 - val_loss: 0.3188 - val_acc: 1.0000\n",
            "Epoch 52/100\n",
            "73/73 [==============================] - 0s 176us/sample - loss: 0.2926 - acc: 0.9041 - val_loss: 0.3203 - val_acc: 0.9688\n",
            "Epoch 53/100\n",
            "73/73 [==============================] - 0s 139us/sample - loss: 0.3119 - acc: 0.8904 - val_loss: 0.3160 - val_acc: 0.9688\n",
            "Epoch 54/100\n",
            "73/73 [==============================] - 0s 179us/sample - loss: 0.3168 - acc: 0.9178 - val_loss: 0.3036 - val_acc: 1.0000\n",
            "Epoch 55/100\n",
            "73/73 [==============================] - 0s 167us/sample - loss: 0.3177 - acc: 0.8767 - val_loss: 0.3035 - val_acc: 1.0000\n",
            "Epoch 56/100\n",
            "73/73 [==============================] - 0s 208us/sample - loss: 0.3364 - acc: 0.9315 - val_loss: 0.2980 - val_acc: 1.0000\n",
            "Epoch 57/100\n",
            "73/73 [==============================] - 0s 144us/sample - loss: 0.2892 - acc: 0.9452 - val_loss: 0.2914 - val_acc: 1.0000\n",
            "Epoch 58/100\n",
            "73/73 [==============================] - 0s 153us/sample - loss: 0.3151 - acc: 0.9041 - val_loss: 0.2905 - val_acc: 0.9688\n",
            "Epoch 59/100\n",
            "73/73 [==============================] - 0s 183us/sample - loss: 0.2995 - acc: 0.9041 - val_loss: 0.2860 - val_acc: 0.9688\n",
            "Epoch 60/100\n",
            "73/73 [==============================] - 0s 156us/sample - loss: 0.2790 - acc: 0.9178 - val_loss: 0.2795 - val_acc: 1.0000\n",
            "Epoch 61/100\n",
            "73/73 [==============================] - 0s 164us/sample - loss: 0.3163 - acc: 0.9041 - val_loss: 0.2761 - val_acc: 1.0000\n",
            "Epoch 62/100\n",
            "73/73 [==============================] - 0s 141us/sample - loss: 0.2907 - acc: 0.8904 - val_loss: 0.2772 - val_acc: 1.0000\n",
            "Epoch 63/100\n",
            "73/73 [==============================] - 0s 137us/sample - loss: 0.2836 - acc: 0.8904 - val_loss: 0.2675 - val_acc: 1.0000\n",
            "Epoch 64/100\n",
            "73/73 [==============================] - 0s 204us/sample - loss: 0.2715 - acc: 0.9452 - val_loss: 0.2641 - val_acc: 0.9688\n",
            "Epoch 65/100\n",
            "73/73 [==============================] - 0s 178us/sample - loss: 0.2714 - acc: 0.9315 - val_loss: 0.2617 - val_acc: 0.9688\n",
            "Epoch 66/100\n",
            "73/73 [==============================] - 0s 154us/sample - loss: 0.2948 - acc: 0.9041 - val_loss: 0.2544 - val_acc: 1.0000\n",
            "Epoch 67/100\n",
            "73/73 [==============================] - 0s 185us/sample - loss: 0.2654 - acc: 0.9452 - val_loss: 0.2514 - val_acc: 1.0000\n",
            "Epoch 68/100\n",
            "73/73 [==============================] - 0s 219us/sample - loss: 0.2908 - acc: 0.9178 - val_loss: 0.2546 - val_acc: 1.0000\n",
            "Epoch 69/100\n",
            "73/73 [==============================] - 0s 179us/sample - loss: 0.2806 - acc: 0.8767 - val_loss: 0.2539 - val_acc: 1.0000\n",
            "Epoch 70/100\n",
            "73/73 [==============================] - 0s 195us/sample - loss: 0.2836 - acc: 0.9041 - val_loss: 0.2415 - val_acc: 1.0000\n",
            "Epoch 71/100\n",
            "73/73 [==============================] - 0s 186us/sample - loss: 0.2604 - acc: 0.9452 - val_loss: 0.2411 - val_acc: 0.9688\n",
            "Epoch 72/100\n",
            "73/73 [==============================] - 0s 180us/sample - loss: 0.2450 - acc: 0.9315 - val_loss: 0.2435 - val_acc: 0.9688\n",
            "Epoch 73/100\n",
            "73/73 [==============================] - 0s 164us/sample - loss: 0.2473 - acc: 0.9452 - val_loss: 0.2402 - val_acc: 0.9688\n",
            "Epoch 74/100\n",
            "73/73 [==============================] - 0s 168us/sample - loss: 0.2543 - acc: 0.9452 - val_loss: 0.2279 - val_acc: 1.0000\n",
            "Epoch 75/100\n",
            "73/73 [==============================] - 0s 166us/sample - loss: 0.2699 - acc: 0.9452 - val_loss: 0.2326 - val_acc: 1.0000\n",
            "Epoch 76/100\n",
            "73/73 [==============================] - 0s 201us/sample - loss: 0.2737 - acc: 0.8904 - val_loss: 0.2262 - val_acc: 1.0000\n",
            "Epoch 77/100\n",
            "73/73 [==============================] - 0s 165us/sample - loss: 0.2520 - acc: 0.9452 - val_loss: 0.2219 - val_acc: 1.0000\n",
            "Epoch 78/100\n",
            "73/73 [==============================] - 0s 177us/sample - loss: 0.2449 - acc: 0.9315 - val_loss: 0.2154 - val_acc: 1.0000\n",
            "Epoch 79/100\n",
            "73/73 [==============================] - 0s 173us/sample - loss: 0.2525 - acc: 0.9178 - val_loss: 0.2136 - val_acc: 1.0000\n",
            "Epoch 80/100\n",
            "73/73 [==============================] - 0s 168us/sample - loss: 0.2441 - acc: 0.9178 - val_loss: 0.2118 - val_acc: 1.0000\n",
            "Epoch 81/100\n",
            "73/73 [==============================] - 0s 190us/sample - loss: 0.2629 - acc: 0.9452 - val_loss: 0.2147 - val_acc: 0.9688\n",
            "Epoch 82/100\n",
            "73/73 [==============================] - 0s 162us/sample - loss: 0.2573 - acc: 0.9178 - val_loss: 0.2073 - val_acc: 0.9688\n",
            "Epoch 83/100\n",
            "73/73 [==============================] - 0s 165us/sample - loss: 0.2609 - acc: 0.9178 - val_loss: 0.2011 - val_acc: 1.0000\n",
            "Epoch 84/100\n",
            "73/73 [==============================] - 0s 153us/sample - loss: 0.2291 - acc: 0.9178 - val_loss: 0.1983 - val_acc: 1.0000\n",
            "Epoch 85/100\n",
            "73/73 [==============================] - 0s 209us/sample - loss: 0.2218 - acc: 0.9452 - val_loss: 0.2012 - val_acc: 0.9688\n",
            "Epoch 86/100\n",
            "73/73 [==============================] - 0s 197us/sample - loss: 0.2307 - acc: 0.9452 - val_loss: 0.2163 - val_acc: 0.9688\n",
            "Epoch 87/100\n",
            "73/73 [==============================] - 0s 163us/sample - loss: 0.2425 - acc: 0.9315 - val_loss: 0.2022 - val_acc: 0.9688\n",
            "Epoch 88/100\n",
            "73/73 [==============================] - 0s 160us/sample - loss: 0.2247 - acc: 0.9315 - val_loss: 0.1891 - val_acc: 1.0000\n",
            "Epoch 89/100\n",
            "73/73 [==============================] - 0s 155us/sample - loss: 0.2205 - acc: 0.9315 - val_loss: 0.1848 - val_acc: 1.0000\n",
            "Epoch 90/100\n",
            "73/73 [==============================] - 0s 158us/sample - loss: 0.1884 - acc: 0.9452 - val_loss: 0.1823 - val_acc: 1.0000\n",
            "Epoch 91/100\n",
            "73/73 [==============================] - 0s 156us/sample - loss: 0.1932 - acc: 0.9863 - val_loss: 0.1805 - val_acc: 1.0000\n",
            "Epoch 92/100\n",
            "73/73 [==============================] - 0s 165us/sample - loss: 0.2199 - acc: 0.9315 - val_loss: 0.1788 - val_acc: 1.0000\n",
            "Epoch 93/100\n",
            "73/73 [==============================] - 0s 151us/sample - loss: 0.2209 - acc: 0.9041 - val_loss: 0.1790 - val_acc: 0.9688\n",
            "Epoch 94/100\n",
            "73/73 [==============================] - 0s 156us/sample - loss: 0.2155 - acc: 0.9589 - val_loss: 0.1741 - val_acc: 1.0000\n",
            "Epoch 95/100\n",
            "73/73 [==============================] - 0s 170us/sample - loss: 0.2159 - acc: 0.9589 - val_loss: 0.1718 - val_acc: 1.0000\n",
            "Epoch 96/100\n",
            "73/73 [==============================] - 0s 176us/sample - loss: 0.2199 - acc: 0.9452 - val_loss: 0.1689 - val_acc: 1.0000\n",
            "Epoch 97/100\n",
            "73/73 [==============================] - 0s 153us/sample - loss: 0.1818 - acc: 0.9452 - val_loss: 0.1698 - val_acc: 1.0000\n",
            "Epoch 98/100\n",
            "73/73 [==============================] - 0s 146us/sample - loss: 0.2124 - acc: 0.9452 - val_loss: 0.1710 - val_acc: 0.9688\n",
            "Epoch 99/100\n",
            "73/73 [==============================] - 0s 146us/sample - loss: 0.1946 - acc: 0.9452 - val_loss: 0.1708 - val_acc: 0.9688\n",
            "Epoch 100/100\n",
            "73/73 [==============================] - 0s 139us/sample - loss: 0.1957 - acc: 0.9452 - val_loss: 0.1634 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbEQVkwDqD3r",
        "colab_type": "code",
        "outputId": "b2330487-351d-4284-ffae-41bdea8128c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training','Testing'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6sjQjOEqD7L",
        "colab_type": "code",
        "outputId": "76de44fa-6b4a-4e1a-ef2d-7f41b1968cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 0s 198us/sample - loss: 0.1348 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13479209542274476, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f06-I3Xchc4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(x_test[0:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg5PdZV1hc59",
        "colab_type": "code",
        "outputId": "9fd90fde-458d-4040-c3df-23f7bdd354eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qfJXNJ8hc7a",
        "colab_type": "code",
        "outputId": "22f89d3b-134d-4c29-8ea0-86b20059fa0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "x_test[0:3],y_test[0:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[6.1, 2.8, 4.7, 1.2],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [7.7, 2.6, 6.9, 2.3]]), array([1, 0, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2AnkaC7hc-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbNinEcXhdAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lFbH0Um_3Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame(data.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3MoNF6FAW9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df = df[[0,1,2]]\n",
        "target_df = df[3]\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_df, target_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5dNu66VAr8u",
        "colab_type": "code",
        "outputId": "79527f89-83c5-4fe4-8faf-8a5afc9515f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(1000, input_dim=3, kernel_initializer='normal', activation='relu'),\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "  tf.keras.layers.Dense(50, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "adam = tf.keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(loss='mse', optimizer=adam, metrics=['mse','mae'])\n",
        "history = model.fit(X_train, y_train, epochs=300, validation_split=0.4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 67 samples, validate on 45 samples\n",
            "Epoch 1/300\n",
            "67/67 [==============================] - 0s 6ms/sample - loss: 3.1736 - mean_squared_error: 3.1736 - mean_absolute_error: 1.5998 - val_loss: 2.1377 - val_mean_squared_error: 2.1377 - val_mean_absolute_error: 1.2715\n",
            "Epoch 2/300\n",
            "67/67 [==============================] - 0s 375us/sample - loss: 1.9540 - mean_squared_error: 1.9540 - mean_absolute_error: 1.1968 - val_loss: 1.2219 - val_mean_squared_error: 1.2219 - val_mean_absolute_error: 0.9003\n",
            "Epoch 3/300\n",
            "67/67 [==============================] - 0s 279us/sample - loss: 1.1187 - mean_squared_error: 1.1187 - mean_absolute_error: 0.8500 - val_loss: 0.7081 - val_mean_squared_error: 0.7081 - val_mean_absolute_error: 0.6848\n",
            "Epoch 4/300\n",
            "67/67 [==============================] - 0s 271us/sample - loss: 0.6389 - mean_squared_error: 0.6389 - mean_absolute_error: 0.6675 - val_loss: 0.4213 - val_mean_squared_error: 0.4213 - val_mean_absolute_error: 0.5561\n",
            "Epoch 5/300\n",
            "67/67 [==============================] - 0s 265us/sample - loss: 0.4004 - mean_squared_error: 0.4004 - mean_absolute_error: 0.5508 - val_loss: 0.2815 - val_mean_squared_error: 0.2815 - val_mean_absolute_error: 0.4552\n",
            "Epoch 6/300\n",
            "67/67 [==============================] - 0s 274us/sample - loss: 0.2808 - mean_squared_error: 0.2808 - mean_absolute_error: 0.4674 - val_loss: 0.2172 - val_mean_squared_error: 0.2172 - val_mean_absolute_error: 0.3853\n",
            "Epoch 7/300\n",
            "67/67 [==============================] - 0s 284us/sample - loss: 0.2212 - mean_squared_error: 0.2212 - mean_absolute_error: 0.4098 - val_loss: 0.1867 - val_mean_squared_error: 0.1867 - val_mean_absolute_error: 0.3480\n",
            "Epoch 8/300\n",
            "67/67 [==============================] - 0s 272us/sample - loss: 0.1934 - mean_squared_error: 0.1934 - mean_absolute_error: 0.3797 - val_loss: 0.1700 - val_mean_squared_error: 0.1700 - val_mean_absolute_error: 0.3321\n",
            "Epoch 9/300\n",
            "67/67 [==============================] - 0s 269us/sample - loss: 0.1787 - mean_squared_error: 0.1787 - mean_absolute_error: 0.3625 - val_loss: 0.1580 - val_mean_squared_error: 0.1580 - val_mean_absolute_error: 0.3270\n",
            "Epoch 10/300\n",
            "67/67 [==============================] - 0s 271us/sample - loss: 0.1649 - mean_squared_error: 0.1649 - mean_absolute_error: 0.3468 - val_loss: 0.1430 - val_mean_squared_error: 0.1430 - val_mean_absolute_error: 0.3152\n",
            "Epoch 11/300\n",
            "67/67 [==============================] - 0s 257us/sample - loss: 0.1481 - mean_squared_error: 0.1481 - mean_absolute_error: 0.3297 - val_loss: 0.1257 - val_mean_squared_error: 0.1257 - val_mean_absolute_error: 0.2950\n",
            "Epoch 12/300\n",
            "67/67 [==============================] - 0s 302us/sample - loss: 0.1286 - mean_squared_error: 0.1286 - mean_absolute_error: 0.3100 - val_loss: 0.1122 - val_mean_squared_error: 0.1122 - val_mean_absolute_error: 0.2758\n",
            "Epoch 13/300\n",
            "67/67 [==============================] - 0s 280us/sample - loss: 0.1149 - mean_squared_error: 0.1149 - mean_absolute_error: 0.2941 - val_loss: 0.1016 - val_mean_squared_error: 0.1016 - val_mean_absolute_error: 0.2555\n",
            "Epoch 14/300\n",
            "67/67 [==============================] - 0s 264us/sample - loss: 0.1024 - mean_squared_error: 0.1024 - mean_absolute_error: 0.2778 - val_loss: 0.0939 - val_mean_squared_error: 0.0939 - val_mean_absolute_error: 0.2394\n",
            "Epoch 15/300\n",
            "67/67 [==============================] - 0s 327us/sample - loss: 0.0938 - mean_squared_error: 0.0938 - mean_absolute_error: 0.2644 - val_loss: 0.0877 - val_mean_squared_error: 0.0877 - val_mean_absolute_error: 0.2264\n",
            "Epoch 16/300\n",
            "67/67 [==============================] - 0s 447us/sample - loss: 0.0857 - mean_squared_error: 0.0857 - mean_absolute_error: 0.2513 - val_loss: 0.0816 - val_mean_squared_error: 0.0816 - val_mean_absolute_error: 0.2150\n",
            "Epoch 17/300\n",
            "67/67 [==============================] - 0s 260us/sample - loss: 0.0790 - mean_squared_error: 0.0790 - mean_absolute_error: 0.2389 - val_loss: 0.0760 - val_mean_squared_error: 0.0760 - val_mean_absolute_error: 0.2040\n",
            "Epoch 18/300\n",
            "67/67 [==============================] - 0s 287us/sample - loss: 0.0724 - mean_squared_error: 0.0724 - mean_absolute_error: 0.2254 - val_loss: 0.0716 - val_mean_squared_error: 0.0716 - val_mean_absolute_error: 0.1953\n",
            "Epoch 19/300\n",
            "67/67 [==============================] - 0s 272us/sample - loss: 0.0673 - mean_squared_error: 0.0673 - mean_absolute_error: 0.2134 - val_loss: 0.0669 - val_mean_squared_error: 0.0669 - val_mean_absolute_error: 0.1891\n",
            "Epoch 20/300\n",
            "67/67 [==============================] - 0s 272us/sample - loss: 0.0614 - mean_squared_error: 0.0614 - mean_absolute_error: 0.2021 - val_loss: 0.0609 - val_mean_squared_error: 0.0609 - val_mean_absolute_error: 0.1902\n",
            "Epoch 21/300\n",
            "67/67 [==============================] - 0s 263us/sample - loss: 0.0567 - mean_squared_error: 0.0567 - mean_absolute_error: 0.1949 - val_loss: 0.0580 - val_mean_squared_error: 0.0580 - val_mean_absolute_error: 0.1925\n",
            "Epoch 22/300\n",
            "67/67 [==============================] - 0s 271us/sample - loss: 0.0542 - mean_squared_error: 0.0542 - mean_absolute_error: 0.1910 - val_loss: 0.0559 - val_mean_squared_error: 0.0559 - val_mean_absolute_error: 0.1890\n",
            "Epoch 23/300\n",
            "67/67 [==============================] - 0s 272us/sample - loss: 0.0514 - mean_squared_error: 0.0514 - mean_absolute_error: 0.1825 - val_loss: 0.0541 - val_mean_squared_error: 0.0541 - val_mean_absolute_error: 0.1819\n",
            "Epoch 24/300\n",
            "67/67 [==============================] - 0s 315us/sample - loss: 0.0497 - mean_squared_error: 0.0497 - mean_absolute_error: 0.1728 - val_loss: 0.0556 - val_mean_squared_error: 0.0556 - val_mean_absolute_error: 0.1745\n",
            "Epoch 25/300\n",
            "67/67 [==============================] - 0s 284us/sample - loss: 0.0512 - mean_squared_error: 0.0512 - mean_absolute_error: 0.1690 - val_loss: 0.0573 - val_mean_squared_error: 0.0573 - val_mean_absolute_error: 0.1720\n",
            "Epoch 26/300\n",
            "67/67 [==============================] - 0s 291us/sample - loss: 0.0501 - mean_squared_error: 0.0501 - mean_absolute_error: 0.1647 - val_loss: 0.0540 - val_mean_squared_error: 0.0540 - val_mean_absolute_error: 0.1732\n",
            "Epoch 27/300\n",
            "67/67 [==============================] - 0s 283us/sample - loss: 0.0469 - mean_squared_error: 0.0469 - mean_absolute_error: 0.1612 - val_loss: 0.0521 - val_mean_squared_error: 0.0521 - val_mean_absolute_error: 0.1798\n",
            "Epoch 28/300\n",
            "67/67 [==============================] - 0s 342us/sample - loss: 0.0471 - mean_squared_error: 0.0471 - mean_absolute_error: 0.1666 - val_loss: 0.0536 - val_mean_squared_error: 0.0536 - val_mean_absolute_error: 0.1892\n",
            "Epoch 29/300\n",
            "67/67 [==============================] - 0s 278us/sample - loss: 0.0488 - mean_squared_error: 0.0488 - mean_absolute_error: 0.1730 - val_loss: 0.0536 - val_mean_squared_error: 0.0536 - val_mean_absolute_error: 0.1893\n",
            "Epoch 30/300\n",
            "67/67 [==============================] - 0s 275us/sample - loss: 0.0478 - mean_squared_error: 0.0478 - mean_absolute_error: 0.1695 - val_loss: 0.0521 - val_mean_squared_error: 0.0521 - val_mean_absolute_error: 0.1825\n",
            "Epoch 31/300\n",
            "67/67 [==============================] - 0s 280us/sample - loss: 0.0457 - mean_squared_error: 0.0457 - mean_absolute_error: 0.1625 - val_loss: 0.0519 - val_mean_squared_error: 0.0519 - val_mean_absolute_error: 0.1769\n",
            "Epoch 32/300\n",
            "67/67 [==============================] - 0s 270us/sample - loss: 0.0455 - mean_squared_error: 0.0455 - mean_absolute_error: 0.1585 - val_loss: 0.0528 - val_mean_squared_error: 0.0528 - val_mean_absolute_error: 0.1727\n",
            "Epoch 33/300\n",
            "67/67 [==============================] - 0s 288us/sample - loss: 0.0461 - mean_squared_error: 0.0461 - mean_absolute_error: 0.1580 - val_loss: 0.0534 - val_mean_squared_error: 0.0534 - val_mean_absolute_error: 0.1712\n",
            "Epoch 34/300\n",
            "67/67 [==============================] - 0s 252us/sample - loss: 0.0456 - mean_squared_error: 0.0456 - mean_absolute_error: 0.1571 - val_loss: 0.0522 - val_mean_squared_error: 0.0522 - val_mean_absolute_error: 0.1728\n",
            "Epoch 35/300\n",
            "67/67 [==============================] - 0s 282us/sample - loss: 0.0448 - mean_squared_error: 0.0448 - mean_absolute_error: 0.1559 - val_loss: 0.0513 - val_mean_squared_error: 0.0513 - val_mean_absolute_error: 0.1746\n",
            "Epoch 36/300\n",
            "67/67 [==============================] - 0s 284us/sample - loss: 0.0442 - mean_squared_error: 0.0442 - mean_absolute_error: 0.1552 - val_loss: 0.0508 - val_mean_squared_error: 0.0508 - val_mean_absolute_error: 0.1754\n",
            "Epoch 37/300\n",
            "67/67 [==============================] - 0s 295us/sample - loss: 0.0441 - mean_squared_error: 0.0441 - mean_absolute_error: 0.1551 - val_loss: 0.0507 - val_mean_squared_error: 0.0507 - val_mean_absolute_error: 0.1747\n",
            "Epoch 38/300\n",
            "67/67 [==============================] - 0s 254us/sample - loss: 0.0438 - mean_squared_error: 0.0438 - mean_absolute_error: 0.1555 - val_loss: 0.0503 - val_mean_squared_error: 0.0503 - val_mean_absolute_error: 0.1759\n",
            "Epoch 39/300\n",
            "67/67 [==============================] - 0s 320us/sample - loss: 0.0434 - mean_squared_error: 0.0434 - mean_absolute_error: 0.1554 - val_loss: 0.0501 - val_mean_squared_error: 0.0501 - val_mean_absolute_error: 0.1767\n",
            "Epoch 40/300\n",
            "67/67 [==============================] - 0s 345us/sample - loss: 0.0435 - mean_squared_error: 0.0435 - mean_absolute_error: 0.1559 - val_loss: 0.0500 - val_mean_squared_error: 0.0500 - val_mean_absolute_error: 0.1774\n",
            "Epoch 41/300\n",
            "67/67 [==============================] - 0s 265us/sample - loss: 0.0433 - mean_squared_error: 0.0433 - mean_absolute_error: 0.1558 - val_loss: 0.0499 - val_mean_squared_error: 0.0499 - val_mean_absolute_error: 0.1776\n",
            "Epoch 42/300\n",
            "67/67 [==============================] - 0s 353us/sample - loss: 0.0431 - mean_squared_error: 0.0431 - mean_absolute_error: 0.1553 - val_loss: 0.0498 - val_mean_squared_error: 0.0498 - val_mean_absolute_error: 0.1770\n",
            "Epoch 43/300\n",
            "67/67 [==============================] - 0s 342us/sample - loss: 0.0429 - mean_squared_error: 0.0429 - mean_absolute_error: 0.1543 - val_loss: 0.0498 - val_mean_squared_error: 0.0498 - val_mean_absolute_error: 0.1751\n",
            "Epoch 44/300\n",
            "67/67 [==============================] - 0s 294us/sample - loss: 0.0427 - mean_squared_error: 0.0427 - mean_absolute_error: 0.1534 - val_loss: 0.0500 - val_mean_squared_error: 0.0500 - val_mean_absolute_error: 0.1737\n",
            "Epoch 45/300\n",
            "67/67 [==============================] - 0s 333us/sample - loss: 0.0429 - mean_squared_error: 0.0429 - mean_absolute_error: 0.1529 - val_loss: 0.0495 - val_mean_squared_error: 0.0495 - val_mean_absolute_error: 0.1754\n",
            "Epoch 46/300\n",
            "67/67 [==============================] - 0s 277us/sample - loss: 0.0425 - mean_squared_error: 0.0425 - mean_absolute_error: 0.1527 - val_loss: 0.0495 - val_mean_squared_error: 0.0495 - val_mean_absolute_error: 0.1776\n",
            "Epoch 47/300\n",
            "67/67 [==============================] - 0s 321us/sample - loss: 0.0432 - mean_squared_error: 0.0432 - mean_absolute_error: 0.1551 - val_loss: 0.0495 - val_mean_squared_error: 0.0495 - val_mean_absolute_error: 0.1783\n",
            "Epoch 48/300\n",
            "67/67 [==============================] - 0s 318us/sample - loss: 0.0427 - mean_squared_error: 0.0427 - mean_absolute_error: 0.1539 - val_loss: 0.0492 - val_mean_squared_error: 0.0492 - val_mean_absolute_error: 0.1764\n",
            "Epoch 49/300\n",
            "67/67 [==============================] - 0s 313us/sample - loss: 0.0422 - mean_squared_error: 0.0422 - mean_absolute_error: 0.1521 - val_loss: 0.0494 - val_mean_squared_error: 0.0494 - val_mean_absolute_error: 0.1735\n",
            "Epoch 50/300\n",
            "67/67 [==============================] - 0s 317us/sample - loss: 0.0425 - mean_squared_error: 0.0425 - mean_absolute_error: 0.1512 - val_loss: 0.0513 - val_mean_squared_error: 0.0513 - val_mean_absolute_error: 0.1694\n",
            "Epoch 51/300\n",
            "67/67 [==============================] - 0s 292us/sample - loss: 0.0445 - mean_squared_error: 0.0445 - mean_absolute_error: 0.1545 - val_loss: 0.0531 - val_mean_squared_error: 0.0531 - val_mean_absolute_error: 0.1671\n",
            "Epoch 52/300\n",
            "67/67 [==============================] - 0s 337us/sample - loss: 0.0447 - mean_squared_error: 0.0447 - mean_absolute_error: 0.1554 - val_loss: 0.0506 - val_mean_squared_error: 0.0506 - val_mean_absolute_error: 0.1674\n",
            "Epoch 53/300\n",
            "67/67 [==============================] - 0s 286us/sample - loss: 0.0430 - mean_squared_error: 0.0430 - mean_absolute_error: 0.1509 - val_loss: 0.0487 - val_mean_squared_error: 0.0487 - val_mean_absolute_error: 0.1702\n",
            "Epoch 54/300\n",
            "67/67 [==============================] - 0s 277us/sample - loss: 0.0414 - mean_squared_error: 0.0414 - mean_absolute_error: 0.1495 - val_loss: 0.0481 - val_mean_squared_error: 0.0481 - val_mean_absolute_error: 0.1737\n",
            "Epoch 55/300\n",
            "67/67 [==============================] - 0s 286us/sample - loss: 0.0417 - mean_squared_error: 0.0417 - mean_absolute_error: 0.1532 - val_loss: 0.0483 - val_mean_squared_error: 0.0483 - val_mean_absolute_error: 0.1772\n",
            "Epoch 56/300\n",
            "67/67 [==============================] - 0s 292us/sample - loss: 0.0422 - mean_squared_error: 0.0422 - mean_absolute_error: 0.1556 - val_loss: 0.0480 - val_mean_squared_error: 0.0480 - val_mean_absolute_error: 0.1765\n",
            "Epoch 57/300\n",
            "67/67 [==============================] - 0s 272us/sample - loss: 0.0415 - mean_squared_error: 0.0415 - mean_absolute_error: 0.1538 - val_loss: 0.0478 - val_mean_squared_error: 0.0478 - val_mean_absolute_error: 0.1724\n",
            "Epoch 58/300\n",
            "67/67 [==============================] - 0s 311us/sample - loss: 0.0410 - mean_squared_error: 0.0410 - mean_absolute_error: 0.1499 - val_loss: 0.0496 - val_mean_squared_error: 0.0496 - val_mean_absolute_error: 0.1658\n",
            "Epoch 59/300\n",
            "67/67 [==============================] - 0s 274us/sample - loss: 0.0434 - mean_squared_error: 0.0434 - mean_absolute_error: 0.1529 - val_loss: 0.0509 - val_mean_squared_error: 0.0509 - val_mean_absolute_error: 0.1642\n",
            "Epoch 60/300\n",
            "67/67 [==============================] - 0s 281us/sample - loss: 0.0432 - mean_squared_error: 0.0432 - mean_absolute_error: 0.1527 - val_loss: 0.0487 - val_mean_squared_error: 0.0487 - val_mean_absolute_error: 0.1677\n",
            "Epoch 61/300\n",
            "67/67 [==============================] - 0s 269us/sample - loss: 0.0416 - mean_squared_error: 0.0416 - mean_absolute_error: 0.1502 - val_loss: 0.0476 - val_mean_squared_error: 0.0476 - val_mean_absolute_error: 0.1733\n",
            "Epoch 62/300\n",
            "67/67 [==============================] - 0s 272us/sample - loss: 0.0422 - mean_squared_error: 0.0422 - mean_absolute_error: 0.1556 - val_loss: 0.0483 - val_mean_squared_error: 0.0483 - val_mean_absolute_error: 0.1793\n",
            "Epoch 63/300\n",
            "67/67 [==============================] - 0s 278us/sample - loss: 0.0424 - mean_squared_error: 0.0424 - mean_absolute_error: 0.1586 - val_loss: 0.0489 - val_mean_squared_error: 0.0489 - val_mean_absolute_error: 0.1818\n",
            "Epoch 64/300\n",
            "67/67 [==============================] - 0s 274us/sample - loss: 0.0431 - mean_squared_error: 0.0431 - mean_absolute_error: 0.1595 - val_loss: 0.0491 - val_mean_squared_error: 0.0491 - val_mean_absolute_error: 0.1825\n",
            "Epoch 65/300\n",
            "67/67 [==============================] - 0s 257us/sample - loss: 0.0429 - mean_squared_error: 0.0429 - mean_absolute_error: 0.1576 - val_loss: 0.0481 - val_mean_squared_error: 0.0481 - val_mean_absolute_error: 0.1793\n",
            "Epoch 66/300\n",
            "67/67 [==============================] - 0s 287us/sample - loss: 0.0413 - mean_squared_error: 0.0413 - mean_absolute_error: 0.1526 - val_loss: 0.0474 - val_mean_squared_error: 0.0474 - val_mean_absolute_error: 0.1727\n",
            "Epoch 67/300\n",
            "67/67 [==============================] - 0s 285us/sample - loss: 0.0405 - mean_squared_error: 0.0405 - mean_absolute_error: 0.1488 - val_loss: 0.0483 - val_mean_squared_error: 0.0483 - val_mean_absolute_error: 0.1686\n",
            "Epoch 68/300\n",
            "67/67 [==============================] - 0s 331us/sample - loss: 0.0406 - mean_squared_error: 0.0406 - mean_absolute_error: 0.1469 - val_loss: 0.0479 - val_mean_squared_error: 0.0479 - val_mean_absolute_error: 0.1694\n",
            "Epoch 69/300\n",
            "67/67 [==============================] - 0s 292us/sample - loss: 0.0403 - mean_squared_error: 0.0403 - mean_absolute_error: 0.1469 - val_loss: 0.0481 - val_mean_squared_error: 0.0481 - val_mean_absolute_error: 0.1681\n",
            "Epoch 70/300\n",
            "67/67 [==============================] - 0s 290us/sample - loss: 0.0409 - mean_squared_error: 0.0409 - mean_absolute_error: 0.1471 - val_loss: 0.0491 - val_mean_squared_error: 0.0491 - val_mean_absolute_error: 0.1658\n",
            "Epoch 71/300\n",
            "67/67 [==============================] - 0s 300us/sample - loss: 0.0411 - mean_squared_error: 0.0411 - mean_absolute_error: 0.1476 - val_loss: 0.0482 - val_mean_squared_error: 0.0482 - val_mean_absolute_error: 0.1666\n",
            "Epoch 72/300\n",
            "67/67 [==============================] - 0s 297us/sample - loss: 0.0404 - mean_squared_error: 0.0404 - mean_absolute_error: 0.1464 - val_loss: 0.0471 - val_mean_squared_error: 0.0471 - val_mean_absolute_error: 0.1685\n",
            "Epoch 73/300\n",
            "67/67 [==============================] - 0s 279us/sample - loss: 0.0396 - mean_squared_error: 0.0396 - mean_absolute_error: 0.1459 - val_loss: 0.0467 - val_mean_squared_error: 0.0467 - val_mean_absolute_error: 0.1735\n",
            "Epoch 74/300\n",
            "67/67 [==============================] - 0s 277us/sample - loss: 0.0400 - mean_squared_error: 0.0400 - mean_absolute_error: 0.1491 - val_loss: 0.0474 - val_mean_squared_error: 0.0474 - val_mean_absolute_error: 0.1777\n",
            "Epoch 75/300\n",
            "67/67 [==============================] - 0s 301us/sample - loss: 0.0413 - mean_squared_error: 0.0413 - mean_absolute_error: 0.1533 - val_loss: 0.0476 - val_mean_squared_error: 0.0476 - val_mean_absolute_error: 0.1791\n",
            "Epoch 76/300\n",
            "67/67 [==============================] - 0s 255us/sample - loss: 0.0419 - mean_squared_error: 0.0419 - mean_absolute_error: 0.1546 - val_loss: 0.0470 - val_mean_squared_error: 0.0470 - val_mean_absolute_error: 0.1769\n",
            "Epoch 77/300\n",
            "67/67 [==============================] - 0s 286us/sample - loss: 0.0404 - mean_squared_error: 0.0404 - mean_absolute_error: 0.1504 - val_loss: 0.0466 - val_mean_squared_error: 0.0466 - val_mean_absolute_error: 0.1682\n",
            "Epoch 78/300\n",
            "67/67 [==============================] - 0s 282us/sample - loss: 0.0397 - mean_squared_error: 0.0397 - mean_absolute_error: 0.1454 - val_loss: 0.0492 - val_mean_squared_error: 0.0492 - val_mean_absolute_error: 0.1630\n",
            "Epoch 79/300\n",
            "67/67 [==============================] - 0s 308us/sample - loss: 0.0411 - mean_squared_error: 0.0411 - mean_absolute_error: 0.1467 - val_loss: 0.0473 - val_mean_squared_error: 0.0473 - val_mean_absolute_error: 0.1651\n",
            "Epoch 80/300\n",
            "67/67 [==============================] - 0s 285us/sample - loss: 0.0395 - mean_squared_error: 0.0395 - mean_absolute_error: 0.1457 - val_loss: 0.0462 - val_mean_squared_error: 0.0462 - val_mean_absolute_error: 0.1725\n",
            "Epoch 81/300\n",
            "67/67 [==============================] - 0s 320us/sample - loss: 0.0392 - mean_squared_error: 0.0392 - mean_absolute_error: 0.1487 - val_loss: 0.0477 - val_mean_squared_error: 0.0477 - val_mean_absolute_error: 0.1801\n",
            "Epoch 82/300\n",
            "67/67 [==============================] - 0s 433us/sample - loss: 0.0423 - mean_squared_error: 0.0423 - mean_absolute_error: 0.1574 - val_loss: 0.0483 - val_mean_squared_error: 0.0483 - val_mean_absolute_error: 0.1817\n",
            "Epoch 83/300\n",
            "67/67 [==============================] - 0s 305us/sample - loss: 0.0419 - mean_squared_error: 0.0419 - mean_absolute_error: 0.1570 - val_loss: 0.0463 - val_mean_squared_error: 0.0463 - val_mean_absolute_error: 0.1740\n",
            "Epoch 84/300\n",
            "67/67 [==============================] - 0s 298us/sample - loss: 0.0395 - mean_squared_error: 0.0395 - mean_absolute_error: 0.1494 - val_loss: 0.0464 - val_mean_squared_error: 0.0464 - val_mean_absolute_error: 0.1667\n",
            "Epoch 85/300\n",
            "67/67 [==============================] - 0s 296us/sample - loss: 0.0394 - mean_squared_error: 0.0394 - mean_absolute_error: 0.1454 - val_loss: 0.0486 - val_mean_squared_error: 0.0486 - val_mean_absolute_error: 0.1624\n",
            "Epoch 86/300\n",
            "67/67 [==============================] - 0s 328us/sample - loss: 0.0413 - mean_squared_error: 0.0413 - mean_absolute_error: 0.1473 - val_loss: 0.0504 - val_mean_squared_error: 0.0504 - val_mean_absolute_error: 0.1622\n",
            "Epoch 87/300\n",
            "67/67 [==============================] - 0s 322us/sample - loss: 0.0423 - mean_squared_error: 0.0423 - mean_absolute_error: 0.1490 - val_loss: 0.0493 - val_mean_squared_error: 0.0493 - val_mean_absolute_error: 0.1622\n",
            "Epoch 88/300\n",
            "67/67 [==============================] - 0s 306us/sample - loss: 0.0412 - mean_squared_error: 0.0412 - mean_absolute_error: 0.1470 - val_loss: 0.0473 - val_mean_squared_error: 0.0473 - val_mean_absolute_error: 0.1632\n",
            "Epoch 89/300\n",
            "67/67 [==============================] - 0s 307us/sample - loss: 0.0399 - mean_squared_error: 0.0399 - mean_absolute_error: 0.1452 - val_loss: 0.0481 - val_mean_squared_error: 0.0481 - val_mean_absolute_error: 0.1625\n",
            "Epoch 90/300\n",
            "67/67 [==============================] - 0s 253us/sample - loss: 0.0407 - mean_squared_error: 0.0407 - mean_absolute_error: 0.1465 - val_loss: 0.0470 - val_mean_squared_error: 0.0470 - val_mean_absolute_error: 0.1637\n",
            "Epoch 91/300\n",
            "67/67 [==============================] - 0s 263us/sample - loss: 0.0397 - mean_squared_error: 0.0397 - mean_absolute_error: 0.1472 - val_loss: 0.0459 - val_mean_squared_error: 0.0459 - val_mean_absolute_error: 0.1729\n",
            "Epoch 92/300\n",
            "67/67 [==============================] - 0s 301us/sample - loss: 0.0406 - mean_squared_error: 0.0406 - mean_absolute_error: 0.1536 - val_loss: 0.0477 - val_mean_squared_error: 0.0477 - val_mean_absolute_error: 0.1805\n",
            "Epoch 93/300\n",
            "67/67 [==============================] - 0s 301us/sample - loss: 0.0418 - mean_squared_error: 0.0418 - mean_absolute_error: 0.1572 - val_loss: 0.0465 - val_mean_squared_error: 0.0465 - val_mean_absolute_error: 0.1768\n",
            "Epoch 94/300\n",
            "67/67 [==============================] - 0s 295us/sample - loss: 0.0401 - mean_squared_error: 0.0401 - mean_absolute_error: 0.1511 - val_loss: 0.0454 - val_mean_squared_error: 0.0454 - val_mean_absolute_error: 0.1683\n",
            "Epoch 95/300\n",
            "67/67 [==============================] - 0s 300us/sample - loss: 0.0383 - mean_squared_error: 0.0383 - mean_absolute_error: 0.1432 - val_loss: 0.0470 - val_mean_squared_error: 0.0470 - val_mean_absolute_error: 0.1630\n",
            "Epoch 96/300\n",
            "67/67 [==============================] - 0s 297us/sample - loss: 0.0397 - mean_squared_error: 0.0397 - mean_absolute_error: 0.1442 - val_loss: 0.0496 - val_mean_squared_error: 0.0496 - val_mean_absolute_error: 0.1624\n",
            "Epoch 97/300\n",
            "67/67 [==============================] - 0s 303us/sample - loss: 0.0408 - mean_squared_error: 0.0408 - mean_absolute_error: 0.1467 - val_loss: 0.0472 - val_mean_squared_error: 0.0472 - val_mean_absolute_error: 0.1630\n",
            "Epoch 98/300\n",
            "67/67 [==============================] - 0s 303us/sample - loss: 0.0382 - mean_squared_error: 0.0382 - mean_absolute_error: 0.1414 - val_loss: 0.0453 - val_mean_squared_error: 0.0453 - val_mean_absolute_error: 0.1673\n",
            "Epoch 99/300\n",
            "67/67 [==============================] - 0s 303us/sample - loss: 0.0376 - mean_squared_error: 0.0376 - mean_absolute_error: 0.1429 - val_loss: 0.0463 - val_mean_squared_error: 0.0463 - val_mean_absolute_error: 0.1761\n",
            "Epoch 100/300\n",
            "67/67 [==============================] - 0s 305us/sample - loss: 0.0405 - mean_squared_error: 0.0405 - mean_absolute_error: 0.1511 - val_loss: 0.0509 - val_mean_squared_error: 0.0509 - val_mean_absolute_error: 0.1871\n",
            "Epoch 101/300\n",
            "67/67 [==============================] - 0s 289us/sample - loss: 0.0457 - mean_squared_error: 0.0457 - mean_absolute_error: 0.1634 - val_loss: 0.0508 - val_mean_squared_error: 0.0508 - val_mean_absolute_error: 0.1867\n",
            "Epoch 102/300\n",
            "67/67 [==============================] - 0s 272us/sample - loss: 0.0447 - mean_squared_error: 0.0447 - mean_absolute_error: 0.1581 - val_loss: 0.0459 - val_mean_squared_error: 0.0459 - val_mean_absolute_error: 0.1740\n",
            "Epoch 103/300\n",
            "67/67 [==============================] - 0s 303us/sample - loss: 0.0399 - mean_squared_error: 0.0399 - mean_absolute_error: 0.1484 - val_loss: 0.0455 - val_mean_squared_error: 0.0455 - val_mean_absolute_error: 0.1645\n",
            "Epoch 104/300\n",
            "67/67 [==============================] - 0s 265us/sample - loss: 0.0377 - mean_squared_error: 0.0377 - mean_absolute_error: 0.1408 - val_loss: 0.0470 - val_mean_squared_error: 0.0470 - val_mean_absolute_error: 0.1629\n",
            "Epoch 105/300\n",
            "67/67 [==============================] - 0s 302us/sample - loss: 0.0390 - mean_squared_error: 0.0390 - mean_absolute_error: 0.1438 - val_loss: 0.0486 - val_mean_squared_error: 0.0486 - val_mean_absolute_error: 0.1634\n",
            "Epoch 106/300\n",
            "67/67 [==============================] - 0s 279us/sample - loss: 0.0399 - mean_squared_error: 0.0399 - mean_absolute_error: 0.1460 - val_loss: 0.0495 - val_mean_squared_error: 0.0495 - val_mean_absolute_error: 0.1638\n",
            "Epoch 107/300\n",
            "67/67 [==============================] - 0s 291us/sample - loss: 0.0410 - mean_squared_error: 0.0410 - mean_absolute_error: 0.1479 - val_loss: 0.0503 - val_mean_squared_error: 0.0503 - val_mean_absolute_error: 0.1634\n",
            "Epoch 108/300\n",
            "67/67 [==============================] - 0s 298us/sample - loss: 0.0410 - mean_squared_error: 0.0410 - mean_absolute_error: 0.1485 - val_loss: 0.0462 - val_mean_squared_error: 0.0462 - val_mean_absolute_error: 0.1623\n",
            "Epoch 109/300\n",
            "67/67 [==============================] - 0s 288us/sample - loss: 0.0378 - mean_squared_error: 0.0378 - mean_absolute_error: 0.1413 - val_loss: 0.0446 - val_mean_squared_error: 0.0446 - val_mean_absolute_error: 0.1672\n",
            "Epoch 110/300\n",
            "67/67 [==============================] - 0s 295us/sample - loss: 0.0378 - mean_squared_error: 0.0378 - mean_absolute_error: 0.1439 - val_loss: 0.0460 - val_mean_squared_error: 0.0460 - val_mean_absolute_error: 0.1759\n",
            "Epoch 111/300\n",
            "67/67 [==============================] - 0s 293us/sample - loss: 0.0402 - mean_squared_error: 0.0402 - mean_absolute_error: 0.1512 - val_loss: 0.0461 - val_mean_squared_error: 0.0461 - val_mean_absolute_error: 0.1766\n",
            "Epoch 112/300\n",
            "67/67 [==============================] - 0s 264us/sample - loss: 0.0391 - mean_squared_error: 0.0391 - mean_absolute_error: 0.1493 - val_loss: 0.0445 - val_mean_squared_error: 0.0445 - val_mean_absolute_error: 0.1648\n",
            "Epoch 113/300\n",
            "67/67 [==============================] - 0s 279us/sample - loss: 0.0385 - mean_squared_error: 0.0385 - mean_absolute_error: 0.1452 - val_loss: 0.0503 - val_mean_squared_error: 0.0503 - val_mean_absolute_error: 0.1593\n",
            "Epoch 114/300\n",
            "67/67 [==============================] - 0s 264us/sample - loss: 0.0425 - mean_squared_error: 0.0425 - mean_absolute_error: 0.1488 - val_loss: 0.0531 - val_mean_squared_error: 0.0531 - val_mean_absolute_error: 0.1604\n",
            "Epoch 115/300\n",
            "67/67 [==============================] - 0s 244us/sample - loss: 0.0439 - mean_squared_error: 0.0439 - mean_absolute_error: 0.1505 - val_loss: 0.0505 - val_mean_squared_error: 0.0505 - val_mean_absolute_error: 0.1590\n",
            "Epoch 116/300\n",
            "67/67 [==============================] - 0s 257us/sample - loss: 0.0413 - mean_squared_error: 0.0413 - mean_absolute_error: 0.1469 - val_loss: 0.0464 - val_mean_squared_error: 0.0464 - val_mean_absolute_error: 0.1602\n",
            "Epoch 117/300\n",
            "67/67 [==============================] - 0s 292us/sample - loss: 0.0388 - mean_squared_error: 0.0388 - mean_absolute_error: 0.1431 - val_loss: 0.0444 - val_mean_squared_error: 0.0444 - val_mean_absolute_error: 0.1630\n",
            "Epoch 118/300\n",
            "67/67 [==============================] - 0s 253us/sample - loss: 0.0372 - mean_squared_error: 0.0372 - mean_absolute_error: 0.1421 - val_loss: 0.0445 - val_mean_squared_error: 0.0445 - val_mean_absolute_error: 0.1627\n",
            "Epoch 119/300\n",
            "67/67 [==============================] - 0s 312us/sample - loss: 0.0375 - mean_squared_error: 0.0375 - mean_absolute_error: 0.1416 - val_loss: 0.0455 - val_mean_squared_error: 0.0455 - val_mean_absolute_error: 0.1609\n",
            "Epoch 120/300\n",
            "67/67 [==============================] - 0s 266us/sample - loss: 0.0377 - mean_squared_error: 0.0377 - mean_absolute_error: 0.1414 - val_loss: 0.0449 - val_mean_squared_error: 0.0449 - val_mean_absolute_error: 0.1616\n",
            "Epoch 121/300\n",
            "67/67 [==============================] - 0s 287us/sample - loss: 0.0370 - mean_squared_error: 0.0370 - mean_absolute_error: 0.1399 - val_loss: 0.0442 - val_mean_squared_error: 0.0442 - val_mean_absolute_error: 0.1639\n",
            "Epoch 122/300\n",
            "67/67 [==============================] - 0s 285us/sample - loss: 0.0369 - mean_squared_error: 0.0369 - mean_absolute_error: 0.1399 - val_loss: 0.0446 - val_mean_squared_error: 0.0446 - val_mean_absolute_error: 0.1641\n",
            "Epoch 123/300\n",
            "67/67 [==============================] - 0s 381us/sample - loss: 0.0371 - mean_squared_error: 0.0371 - mean_absolute_error: 0.1396 - val_loss: 0.0447 - val_mean_squared_error: 0.0447 - val_mean_absolute_error: 0.1645\n",
            "Epoch 124/300\n",
            "67/67 [==============================] - 0s 331us/sample - loss: 0.0369 - mean_squared_error: 0.0369 - mean_absolute_error: 0.1395 - val_loss: 0.0445 - val_mean_squared_error: 0.0445 - val_mean_absolute_error: 0.1691\n",
            "Epoch 125/300\n",
            "67/67 [==============================] - 0s 260us/sample - loss: 0.0384 - mean_squared_error: 0.0384 - mean_absolute_error: 0.1442 - val_loss: 0.0469 - val_mean_squared_error: 0.0469 - val_mean_absolute_error: 0.1780\n",
            "Epoch 126/300\n",
            "67/67 [==============================] - 0s 297us/sample - loss: 0.0418 - mean_squared_error: 0.0418 - mean_absolute_error: 0.1543 - val_loss: 0.0465 - val_mean_squared_error: 0.0465 - val_mean_absolute_error: 0.1772\n",
            "Epoch 127/300\n",
            "67/67 [==============================] - 0s 282us/sample - loss: 0.0403 - mean_squared_error: 0.0403 - mean_absolute_error: 0.1510 - val_loss: 0.0442 - val_mean_squared_error: 0.0442 - val_mean_absolute_error: 0.1689\n",
            "Epoch 128/300\n",
            "67/67 [==============================] - 0s 262us/sample - loss: 0.0372 - mean_squared_error: 0.0372 - mean_absolute_error: 0.1421 - val_loss: 0.0439 - val_mean_squared_error: 0.0439 - val_mean_absolute_error: 0.1645\n",
            "Epoch 129/300\n",
            "67/67 [==============================] - 0s 282us/sample - loss: 0.0368 - mean_squared_error: 0.0368 - mean_absolute_error: 0.1394 - val_loss: 0.0455 - val_mean_squared_error: 0.0455 - val_mean_absolute_error: 0.1616\n",
            "Epoch 130/300\n",
            "67/67 [==============================] - 0s 270us/sample - loss: 0.0382 - mean_squared_error: 0.0382 - mean_absolute_error: 0.1413 - val_loss: 0.0458 - val_mean_squared_error: 0.0458 - val_mean_absolute_error: 0.1612\n",
            "Epoch 131/300\n",
            "67/67 [==============================] - 0s 270us/sample - loss: 0.0368 - mean_squared_error: 0.0368 - mean_absolute_error: 0.1388 - val_loss: 0.0439 - val_mean_squared_error: 0.0439 - val_mean_absolute_error: 0.1638\n",
            "Epoch 132/300\n",
            "67/67 [==============================] - 0s 289us/sample - loss: 0.0374 - mean_squared_error: 0.0374 - mean_absolute_error: 0.1414 - val_loss: 0.0445 - val_mean_squared_error: 0.0445 - val_mean_absolute_error: 0.1707\n",
            "Epoch 133/300\n",
            "67/67 [==============================] - 0s 291us/sample - loss: 0.0377 - mean_squared_error: 0.0377 - mean_absolute_error: 0.1436 - val_loss: 0.0441 - val_mean_squared_error: 0.0441 - val_mean_absolute_error: 0.1684\n",
            "Epoch 134/300\n",
            "67/67 [==============================] - 0s 293us/sample - loss: 0.0371 - mean_squared_error: 0.0371 - mean_absolute_error: 0.1426 - val_loss: 0.0440 - val_mean_squared_error: 0.0440 - val_mean_absolute_error: 0.1674\n",
            "Epoch 135/300\n",
            "67/67 [==============================] - 0s 265us/sample - loss: 0.0369 - mean_squared_error: 0.0369 - mean_absolute_error: 0.1408 - val_loss: 0.0438 - val_mean_squared_error: 0.0438 - val_mean_absolute_error: 0.1649\n",
            "Epoch 136/300\n",
            "67/67 [==============================] - 0s 324us/sample - loss: 0.0366 - mean_squared_error: 0.0366 - mean_absolute_error: 0.1399 - val_loss: 0.0441 - val_mean_squared_error: 0.0441 - val_mean_absolute_error: 0.1681\n",
            "Epoch 137/300\n",
            "67/67 [==============================] - 0s 303us/sample - loss: 0.0371 - mean_squared_error: 0.0371 - mean_absolute_error: 0.1417 - val_loss: 0.0440 - val_mean_squared_error: 0.0440 - val_mean_absolute_error: 0.1664\n",
            "Epoch 138/300\n",
            "67/67 [==============================] - 0s 298us/sample - loss: 0.0366 - mean_squared_error: 0.0366 - mean_absolute_error: 0.1403 - val_loss: 0.0441 - val_mean_squared_error: 0.0441 - val_mean_absolute_error: 0.1620\n",
            "Epoch 139/300\n",
            "67/67 [==============================] - 0s 280us/sample - loss: 0.0364 - mean_squared_error: 0.0364 - mean_absolute_error: 0.1393 - val_loss: 0.0470 - val_mean_squared_error: 0.0470 - val_mean_absolute_error: 0.1603\n",
            "Epoch 140/300\n",
            "67/67 [==============================] - 0s 251us/sample - loss: 0.0396 - mean_squared_error: 0.0396 - mean_absolute_error: 0.1450 - val_loss: 0.0505 - val_mean_squared_error: 0.0505 - val_mean_absolute_error: 0.1608\n",
            "Epoch 141/300\n",
            "67/67 [==============================] - 0s 286us/sample - loss: 0.0410 - mean_squared_error: 0.0410 - mean_absolute_error: 0.1473 - val_loss: 0.0464 - val_mean_squared_error: 0.0464 - val_mean_absolute_error: 0.1593\n",
            "Epoch 142/300\n",
            "67/67 [==============================] - 0s 286us/sample - loss: 0.0372 - mean_squared_error: 0.0372 - mean_absolute_error: 0.1401 - val_loss: 0.0438 - val_mean_squared_error: 0.0438 - val_mean_absolute_error: 0.1608\n",
            "Epoch 143/300\n",
            "67/67 [==============================] - 0s 295us/sample - loss: 0.0362 - mean_squared_error: 0.0362 - mean_absolute_error: 0.1385 - val_loss: 0.0433 - val_mean_squared_error: 0.0433 - val_mean_absolute_error: 0.1622\n",
            "Epoch 144/300\n",
            "67/67 [==============================] - 0s 264us/sample - loss: 0.0358 - mean_squared_error: 0.0358 - mean_absolute_error: 0.1381 - val_loss: 0.0435 - val_mean_squared_error: 0.0435 - val_mean_absolute_error: 0.1682\n",
            "Epoch 145/300\n",
            "67/67 [==============================] - 0s 250us/sample - loss: 0.0372 - mean_squared_error: 0.0372 - mean_absolute_error: 0.1425 - val_loss: 0.0438 - val_mean_squared_error: 0.0438 - val_mean_absolute_error: 0.1698\n",
            "Epoch 146/300\n",
            "67/67 [==============================] - 0s 277us/sample - loss: 0.0367 - mean_squared_error: 0.0367 - mean_absolute_error: 0.1431 - val_loss: 0.0431 - val_mean_squared_error: 0.0431 - val_mean_absolute_error: 0.1628\n",
            "Epoch 147/300\n",
            "67/67 [==============================] - 0s 253us/sample - loss: 0.0367 - mean_squared_error: 0.0367 - mean_absolute_error: 0.1401 - val_loss: 0.0456 - val_mean_squared_error: 0.0456 - val_mean_absolute_error: 0.1596\n",
            "Epoch 148/300\n",
            "67/67 [==============================] - 0s 274us/sample - loss: 0.0375 - mean_squared_error: 0.0375 - mean_absolute_error: 0.1400 - val_loss: 0.0458 - val_mean_squared_error: 0.0458 - val_mean_absolute_error: 0.1594\n",
            "Epoch 149/300\n",
            "67/67 [==============================] - 0s 262us/sample - loss: 0.0374 - mean_squared_error: 0.0374 - mean_absolute_error: 0.1397 - val_loss: 0.0447 - val_mean_squared_error: 0.0447 - val_mean_absolute_error: 0.1600\n",
            "Epoch 150/300\n",
            "67/67 [==============================] - 0s 318us/sample - loss: 0.0363 - mean_squared_error: 0.0363 - mean_absolute_error: 0.1383 - val_loss: 0.0432 - val_mean_squared_error: 0.0432 - val_mean_absolute_error: 0.1615\n",
            "Epoch 151/300\n",
            "67/67 [==============================] - 0s 311us/sample - loss: 0.0354 - mean_squared_error: 0.0354 - mean_absolute_error: 0.1375 - val_loss: 0.0428 - val_mean_squared_error: 0.0428 - val_mean_absolute_error: 0.1643\n",
            "Epoch 152/300\n",
            "67/67 [==============================] - 0s 308us/sample - loss: 0.0358 - mean_squared_error: 0.0358 - mean_absolute_error: 0.1387 - val_loss: 0.0432 - val_mean_squared_error: 0.0432 - val_mean_absolute_error: 0.1675\n",
            "Epoch 153/300\n",
            "67/67 [==============================] - 0s 298us/sample - loss: 0.0366 - mean_squared_error: 0.0366 - mean_absolute_error: 0.1412 - val_loss: 0.0428 - val_mean_squared_error: 0.0428 - val_mean_absolute_error: 0.1635\n",
            "Epoch 154/300\n",
            "67/67 [==============================] - 0s 298us/sample - loss: 0.0355 - mean_squared_error: 0.0355 - mean_absolute_error: 0.1373 - val_loss: 0.0449 - val_mean_squared_error: 0.0449 - val_mean_absolute_error: 0.1592\n",
            "Epoch 155/300\n",
            "67/67 [==============================] - 0s 279us/sample - loss: 0.0367 - mean_squared_error: 0.0367 - mean_absolute_error: 0.1389 - val_loss: 0.0472 - val_mean_squared_error: 0.0472 - val_mean_absolute_error: 0.1588\n",
            "Epoch 156/300\n",
            "67/67 [==============================] - 0s 264us/sample - loss: 0.0386 - mean_squared_error: 0.0386 - mean_absolute_error: 0.1415 - val_loss: 0.0452 - val_mean_squared_error: 0.0452 - val_mean_absolute_error: 0.1595\n",
            "Epoch 157/300\n",
            "67/67 [==============================] - 0s 301us/sample - loss: 0.0357 - mean_squared_error: 0.0357 - mean_absolute_error: 0.1367 - val_loss: 0.0427 - val_mean_squared_error: 0.0427 - val_mean_absolute_error: 0.1639\n",
            "Epoch 158/300\n",
            "67/67 [==============================] - 0s 261us/sample - loss: 0.0361 - mean_squared_error: 0.0361 - mean_absolute_error: 0.1400 - val_loss: 0.0436 - val_mean_squared_error: 0.0436 - val_mean_absolute_error: 0.1699\n",
            "Epoch 159/300\n",
            "67/67 [==============================] - 0s 297us/sample - loss: 0.0377 - mean_squared_error: 0.0377 - mean_absolute_error: 0.1447 - val_loss: 0.0427 - val_mean_squared_error: 0.0427 - val_mean_absolute_error: 0.1654\n",
            "Epoch 160/300\n",
            "67/67 [==============================] - 0s 256us/sample - loss: 0.0358 - mean_squared_error: 0.0358 - mean_absolute_error: 0.1374 - val_loss: 0.0457 - val_mean_squared_error: 0.0457 - val_mean_absolute_error: 0.1590\n",
            "Epoch 161/300\n",
            "67/67 [==============================] - 0s 306us/sample - loss: 0.0383 - mean_squared_error: 0.0383 - mean_absolute_error: 0.1406 - val_loss: 0.0474 - val_mean_squared_error: 0.0474 - val_mean_absolute_error: 0.1591\n",
            "Epoch 162/300\n",
            "67/67 [==============================] - 0s 335us/sample - loss: 0.0378 - mean_squared_error: 0.0378 - mean_absolute_error: 0.1410 - val_loss: 0.0435 - val_mean_squared_error: 0.0435 - val_mean_absolute_error: 0.1597\n",
            "Epoch 163/300\n",
            "67/67 [==============================] - 0s 344us/sample - loss: 0.0355 - mean_squared_error: 0.0355 - mean_absolute_error: 0.1357 - val_loss: 0.0426 - val_mean_squared_error: 0.0426 - val_mean_absolute_error: 0.1610\n",
            "Epoch 164/300\n",
            "67/67 [==============================] - 0s 300us/sample - loss: 0.0354 - mean_squared_error: 0.0354 - mean_absolute_error: 0.1374 - val_loss: 0.0427 - val_mean_squared_error: 0.0427 - val_mean_absolute_error: 0.1623\n",
            "Epoch 165/300\n",
            "67/67 [==============================] - 0s 274us/sample - loss: 0.0356 - mean_squared_error: 0.0356 - mean_absolute_error: 0.1384 - val_loss: 0.0427 - val_mean_squared_error: 0.0427 - val_mean_absolute_error: 0.1622\n",
            "Epoch 166/300\n",
            "67/67 [==============================] - 0s 246us/sample - loss: 0.0356 - mean_squared_error: 0.0356 - mean_absolute_error: 0.1390 - val_loss: 0.0426 - val_mean_squared_error: 0.0426 - val_mean_absolute_error: 0.1636\n",
            "Epoch 167/300\n",
            "67/67 [==============================] - 0s 281us/sample - loss: 0.0355 - mean_squared_error: 0.0355 - mean_absolute_error: 0.1388 - val_loss: 0.0425 - val_mean_squared_error: 0.0425 - val_mean_absolute_error: 0.1611\n",
            "Epoch 168/300\n",
            "67/67 [==============================] - 0s 299us/sample - loss: 0.0365 - mean_squared_error: 0.0365 - mean_absolute_error: 0.1393 - val_loss: 0.0424 - val_mean_squared_error: 0.0424 - val_mean_absolute_error: 0.1629\n",
            "Epoch 169/300\n",
            "67/67 [==============================] - 0s 252us/sample - loss: 0.0370 - mean_squared_error: 0.0370 - mean_absolute_error: 0.1415 - val_loss: 0.0453 - val_mean_squared_error: 0.0453 - val_mean_absolute_error: 0.1744\n",
            "Epoch 170/300\n",
            "67/67 [==============================] - 0s 274us/sample - loss: 0.0390 - mean_squared_error: 0.0390 - mean_absolute_error: 0.1479 - val_loss: 0.0433 - val_mean_squared_error: 0.0433 - val_mean_absolute_error: 0.1687\n",
            "Epoch 171/300\n",
            "67/67 [==============================] - 0s 274us/sample - loss: 0.0367 - mean_squared_error: 0.0367 - mean_absolute_error: 0.1414 - val_loss: 0.0426 - val_mean_squared_error: 0.0426 - val_mean_absolute_error: 0.1619\n",
            "Epoch 172/300\n",
            "67/67 [==============================] - 0s 262us/sample - loss: 0.0354 - mean_squared_error: 0.0354 - mean_absolute_error: 0.1383 - val_loss: 0.0428 - val_mean_squared_error: 0.0428 - val_mean_absolute_error: 0.1613\n",
            "Epoch 173/300\n",
            "67/67 [==============================] - 0s 252us/sample - loss: 0.0356 - mean_squared_error: 0.0356 - mean_absolute_error: 0.1392 - val_loss: 0.0428 - val_mean_squared_error: 0.0428 - val_mean_absolute_error: 0.1622\n",
            "Epoch 174/300\n",
            "67/67 [==============================] - 0s 294us/sample - loss: 0.0356 - mean_squared_error: 0.0356 - mean_absolute_error: 0.1400 - val_loss: 0.0427 - val_mean_squared_error: 0.0427 - val_mean_absolute_error: 0.1637\n",
            "Epoch 175/300\n",
            "67/67 [==============================] - 0s 259us/sample - loss: 0.0357 - mean_squared_error: 0.0357 - mean_absolute_error: 0.1409 - val_loss: 0.0426 - val_mean_squared_error: 0.0426 - val_mean_absolute_error: 0.1640\n",
            "Epoch 176/300\n",
            "67/67 [==============================] - 0s 263us/sample - loss: 0.0356 - mean_squared_error: 0.0356 - mean_absolute_error: 0.1396 - val_loss: 0.0429 - val_mean_squared_error: 0.0429 - val_mean_absolute_error: 0.1598\n",
            "Epoch 177/300\n",
            "67/67 [==============================] - 0s 266us/sample - loss: 0.0355 - mean_squared_error: 0.0355 - mean_absolute_error: 0.1382 - val_loss: 0.0441 - val_mean_squared_error: 0.0441 - val_mean_absolute_error: 0.1577\n",
            "Epoch 178/300\n",
            "67/67 [==============================] - 0s 291us/sample - loss: 0.0368 - mean_squared_error: 0.0368 - mean_absolute_error: 0.1387 - val_loss: 0.0454 - val_mean_squared_error: 0.0454 - val_mean_absolute_error: 0.1567\n",
            "Epoch 179/300\n",
            "67/67 [==============================] - 0s 253us/sample - loss: 0.0378 - mean_squared_error: 0.0378 - mean_absolute_error: 0.1404 - val_loss: 0.0454 - val_mean_squared_error: 0.0454 - val_mean_absolute_error: 0.1566\n",
            "Epoch 180/300\n",
            "67/67 [==============================] - 0s 256us/sample - loss: 0.0369 - mean_squared_error: 0.0369 - mean_absolute_error: 0.1387 - val_loss: 0.0436 - val_mean_squared_error: 0.0436 - val_mean_absolute_error: 0.1583\n",
            "Epoch 181/300\n",
            "67/67 [==============================] - 0s 281us/sample - loss: 0.0357 - mean_squared_error: 0.0357 - mean_absolute_error: 0.1377 - val_loss: 0.0423 - val_mean_squared_error: 0.0423 - val_mean_absolute_error: 0.1608\n",
            "Epoch 182/300\n",
            "67/67 [==============================] - 0s 317us/sample - loss: 0.0354 - mean_squared_error: 0.0354 - mean_absolute_error: 0.1398 - val_loss: 0.0426 - val_mean_squared_error: 0.0426 - val_mean_absolute_error: 0.1671\n",
            "Epoch 183/300\n",
            "67/67 [==============================] - 0s 297us/sample - loss: 0.0367 - mean_squared_error: 0.0367 - mean_absolute_error: 0.1446 - val_loss: 0.0442 - val_mean_squared_error: 0.0442 - val_mean_absolute_error: 0.1724\n",
            "Epoch 184/300\n",
            "67/67 [==============================] - 0s 289us/sample - loss: 0.0386 - mean_squared_error: 0.0386 - mean_absolute_error: 0.1496 - val_loss: 0.0436 - val_mean_squared_error: 0.0436 - val_mean_absolute_error: 0.1705\n",
            "Epoch 185/300\n",
            "67/67 [==============================] - 0s 335us/sample - loss: 0.0376 - mean_squared_error: 0.0376 - mean_absolute_error: 0.1457 - val_loss: 0.0425 - val_mean_squared_error: 0.0425 - val_mean_absolute_error: 0.1671\n",
            "Epoch 186/300\n",
            "67/67 [==============================] - 0s 257us/sample - loss: 0.0361 - mean_squared_error: 0.0361 - mean_absolute_error: 0.1411 - val_loss: 0.0421 - val_mean_squared_error: 0.0421 - val_mean_absolute_error: 0.1629\n",
            "Epoch 187/300\n",
            "67/67 [==============================] - 0s 284us/sample - loss: 0.0351 - mean_squared_error: 0.0351 - mean_absolute_error: 0.1370 - val_loss: 0.0430 - val_mean_squared_error: 0.0430 - val_mean_absolute_error: 0.1602\n",
            "Epoch 188/300\n",
            "67/67 [==============================] - 0s 263us/sample - loss: 0.0354 - mean_squared_error: 0.0354 - mean_absolute_error: 0.1355 - val_loss: 0.0437 - val_mean_squared_error: 0.0437 - val_mean_absolute_error: 0.1594\n",
            "Epoch 189/300\n",
            "67/67 [==============================] - 0s 268us/sample - loss: 0.0357 - mean_squared_error: 0.0357 - mean_absolute_error: 0.1360 - val_loss: 0.0428 - val_mean_squared_error: 0.0428 - val_mean_absolute_error: 0.1603\n",
            "Epoch 190/300\n",
            "67/67 [==============================] - 0s 279us/sample - loss: 0.0351 - mean_squared_error: 0.0351 - mean_absolute_error: 0.1348 - val_loss: 0.0431 - val_mean_squared_error: 0.0431 - val_mean_absolute_error: 0.1599\n",
            "Epoch 191/300\n",
            "67/67 [==============================] - 0s 300us/sample - loss: 0.0356 - mean_squared_error: 0.0356 - mean_absolute_error: 0.1355 - val_loss: 0.0460 - val_mean_squared_error: 0.0460 - val_mean_absolute_error: 0.1588\n",
            "Epoch 192/300\n",
            "67/67 [==============================] - 0s 293us/sample - loss: 0.0377 - mean_squared_error: 0.0377 - mean_absolute_error: 0.1393 - val_loss: 0.0468 - val_mean_squared_error: 0.0468 - val_mean_absolute_error: 0.1585\n",
            "Epoch 193/300\n",
            "67/67 [==============================] - 0s 259us/sample - loss: 0.0375 - mean_squared_error: 0.0375 - mean_absolute_error: 0.1392 - val_loss: 0.0430 - val_mean_squared_error: 0.0430 - val_mean_absolute_error: 0.1597\n",
            "Epoch 194/300\n",
            "67/67 [==============================] - 0s 271us/sample - loss: 0.0344 - mean_squared_error: 0.0344 - mean_absolute_error: 0.1348 - val_loss: 0.0444 - val_mean_squared_error: 0.0444 - val_mean_absolute_error: 0.1717\n",
            "Epoch 195/300\n",
            "67/67 [==============================] - 0s 317us/sample - loss: 0.0392 - mean_squared_error: 0.0392 - mean_absolute_error: 0.1493 - val_loss: 0.0511 - val_mean_squared_error: 0.0511 - val_mean_absolute_error: 0.1857\n",
            "Epoch 196/300\n",
            "67/67 [==============================] - 0s 285us/sample - loss: 0.0485 - mean_squared_error: 0.0485 - mean_absolute_error: 0.1707 - val_loss: 0.0505 - val_mean_squared_error: 0.0505 - val_mean_absolute_error: 0.1844\n",
            "Epoch 197/300\n",
            "67/67 [==============================] - 0s 323us/sample - loss: 0.0430 - mean_squared_error: 0.0430 - mean_absolute_error: 0.1579 - val_loss: 0.0422 - val_mean_squared_error: 0.0422 - val_mean_absolute_error: 0.1641\n",
            "Epoch 198/300\n",
            "67/67 [==============================] - 0s 244us/sample - loss: 0.0348 - mean_squared_error: 0.0348 - mean_absolute_error: 0.1367 - val_loss: 0.0472 - val_mean_squared_error: 0.0472 - val_mean_absolute_error: 0.1565\n",
            "Epoch 199/300\n",
            "67/67 [==============================] - 0s 277us/sample - loss: 0.0397 - mean_squared_error: 0.0397 - mean_absolute_error: 0.1458 - val_loss: 0.0527 - val_mean_squared_error: 0.0527 - val_mean_absolute_error: 0.1593\n",
            "Epoch 200/300\n",
            "67/67 [==============================] - 0s 253us/sample - loss: 0.0427 - mean_squared_error: 0.0427 - mean_absolute_error: 0.1488 - val_loss: 0.0481 - val_mean_squared_error: 0.0481 - val_mean_absolute_error: 0.1553\n",
            "Epoch 201/300\n",
            "67/67 [==============================] - 0s 244us/sample - loss: 0.0393 - mean_squared_error: 0.0393 - mean_absolute_error: 0.1429 - val_loss: 0.0455 - val_mean_squared_error: 0.0455 - val_mean_absolute_error: 0.1556\n",
            "Epoch 202/300\n",
            "67/67 [==============================] - 0s 253us/sample - loss: 0.0374 - mean_squared_error: 0.0374 - mean_absolute_error: 0.1395 - val_loss: 0.0436 - val_mean_squared_error: 0.0436 - val_mean_absolute_error: 0.1576\n",
            "Epoch 203/300\n",
            "67/67 [==============================] - 0s 272us/sample - loss: 0.0359 - mean_squared_error: 0.0359 - mean_absolute_error: 0.1399 - val_loss: 0.0421 - val_mean_squared_error: 0.0421 - val_mean_absolute_error: 0.1627\n",
            "Epoch 204/300\n",
            "67/67 [==============================] - 0s 312us/sample - loss: 0.0359 - mean_squared_error: 0.0359 - mean_absolute_error: 0.1412 - val_loss: 0.0421 - val_mean_squared_error: 0.0421 - val_mean_absolute_error: 0.1648\n",
            "Epoch 205/300\n",
            "67/67 [==============================] - 0s 280us/sample - loss: 0.0354 - mean_squared_error: 0.0354 - mean_absolute_error: 0.1395 - val_loss: 0.0419 - val_mean_squared_error: 0.0419 - val_mean_absolute_error: 0.1635\n",
            "Epoch 206/300\n",
            "67/67 [==============================] - 0s 376us/sample - loss: 0.0351 - mean_squared_error: 0.0351 - mean_absolute_error: 0.1369 - val_loss: 0.0418 - val_mean_squared_error: 0.0418 - val_mean_absolute_error: 0.1606\n",
            "Epoch 207/300\n",
            "67/67 [==============================] - 0s 267us/sample - loss: 0.0344 - mean_squared_error: 0.0344 - mean_absolute_error: 0.1333 - val_loss: 0.0426 - val_mean_squared_error: 0.0426 - val_mean_absolute_error: 0.1582\n",
            "Epoch 208/300\n",
            "67/67 [==============================] - 0s 245us/sample - loss: 0.0346 - mean_squared_error: 0.0346 - mean_absolute_error: 0.1344 - val_loss: 0.0441 - val_mean_squared_error: 0.0441 - val_mean_absolute_error: 0.1570\n",
            "Epoch 209/300\n",
            "67/67 [==============================] - 0s 271us/sample - loss: 0.0358 - mean_squared_error: 0.0358 - mean_absolute_error: 0.1371 - val_loss: 0.0446 - val_mean_squared_error: 0.0446 - val_mean_absolute_error: 0.1563\n",
            "Epoch 210/300\n",
            "67/67 [==============================] - 0s 268us/sample - loss: 0.0362 - mean_squared_error: 0.0362 - mean_absolute_error: 0.1373 - val_loss: 0.0436 - val_mean_squared_error: 0.0436 - val_mean_absolute_error: 0.1562\n",
            "Epoch 211/300\n",
            "67/67 [==============================] - 0s 260us/sample - loss: 0.0352 - mean_squared_error: 0.0352 - mean_absolute_error: 0.1353 - val_loss: 0.0416 - val_mean_squared_error: 0.0416 - val_mean_absolute_error: 0.1591\n",
            "Epoch 212/300\n",
            "67/67 [==============================] - 0s 282us/sample - loss: 0.0342 - mean_squared_error: 0.0342 - mean_absolute_error: 0.1368 - val_loss: 0.0431 - val_mean_squared_error: 0.0431 - val_mean_absolute_error: 0.1690\n",
            "Epoch 213/300\n",
            "67/67 [==============================] - 0s 302us/sample - loss: 0.0383 - mean_squared_error: 0.0383 - mean_absolute_error: 0.1477 - val_loss: 0.0454 - val_mean_squared_error: 0.0454 - val_mean_absolute_error: 0.1747\n",
            "Epoch 214/300\n",
            "67/67 [==============================] - 0s 245us/sample - loss: 0.0397 - mean_squared_error: 0.0397 - mean_absolute_error: 0.1510 - val_loss: 0.0420 - val_mean_squared_error: 0.0420 - val_mean_absolute_error: 0.1649\n",
            "Epoch 215/300\n",
            "67/67 [==============================] - 0s 265us/sample - loss: 0.0341 - mean_squared_error: 0.0341 - mean_absolute_error: 0.1348 - val_loss: 0.0447 - val_mean_squared_error: 0.0447 - val_mean_absolute_error: 0.1559\n",
            "Epoch 216/300\n",
            "67/67 [==============================] - 0s 250us/sample - loss: 0.0365 - mean_squared_error: 0.0365 - mean_absolute_error: 0.1378 - val_loss: 0.0534 - val_mean_squared_error: 0.0534 - val_mean_absolute_error: 0.1609\n",
            "Epoch 217/300\n",
            "67/67 [==============================] - 0s 316us/sample - loss: 0.0441 - mean_squared_error: 0.0441 - mean_absolute_error: 0.1538 - val_loss: 0.0537 - val_mean_squared_error: 0.0537 - val_mean_absolute_error: 0.1602\n",
            "Epoch 218/300\n",
            "67/67 [==============================] - 0s 266us/sample - loss: 0.0427 - mean_squared_error: 0.0427 - mean_absolute_error: 0.1500 - val_loss: 0.0446 - val_mean_squared_error: 0.0446 - val_mean_absolute_error: 0.1558\n",
            "Epoch 219/300\n",
            "67/67 [==============================] - 0s 288us/sample - loss: 0.0358 - mean_squared_error: 0.0358 - mean_absolute_error: 0.1364 - val_loss: 0.0416 - val_mean_squared_error: 0.0416 - val_mean_absolute_error: 0.1600\n",
            "Epoch 220/300\n",
            "67/67 [==============================] - 0s 298us/sample - loss: 0.0344 - mean_squared_error: 0.0344 - mean_absolute_error: 0.1369 - val_loss: 0.0416 - val_mean_squared_error: 0.0416 - val_mean_absolute_error: 0.1602\n",
            "Epoch 221/300\n",
            "67/67 [==============================] - 0s 298us/sample - loss: 0.0345 - mean_squared_error: 0.0345 - mean_absolute_error: 0.1366 - val_loss: 0.0420 - val_mean_squared_error: 0.0420 - val_mean_absolute_error: 0.1591\n",
            "Epoch 222/300\n",
            "67/67 [==============================] - 0s 308us/sample - loss: 0.0348 - mean_squared_error: 0.0348 - mean_absolute_error: 0.1368 - val_loss: 0.0436 - val_mean_squared_error: 0.0436 - val_mean_absolute_error: 0.1574\n",
            "Epoch 223/300\n",
            "67/67 [==============================] - 0s 292us/sample - loss: 0.0355 - mean_squared_error: 0.0355 - mean_absolute_error: 0.1364 - val_loss: 0.0443 - val_mean_squared_error: 0.0443 - val_mean_absolute_error: 0.1571\n",
            "Epoch 224/300\n",
            "67/67 [==============================] - 0s 266us/sample - loss: 0.0359 - mean_squared_error: 0.0359 - mean_absolute_error: 0.1365 - val_loss: 0.0427 - val_mean_squared_error: 0.0427 - val_mean_absolute_error: 0.1579\n",
            "Epoch 225/300\n",
            "67/67 [==============================] - 0s 262us/sample - loss: 0.0351 - mean_squared_error: 0.0351 - mean_absolute_error: 0.1361 - val_loss: 0.0414 - val_mean_squared_error: 0.0414 - val_mean_absolute_error: 0.1598\n",
            "Epoch 226/300\n",
            "67/67 [==============================] - 0s 289us/sample - loss: 0.0343 - mean_squared_error: 0.0343 - mean_absolute_error: 0.1354 - val_loss: 0.0414 - val_mean_squared_error: 0.0414 - val_mean_absolute_error: 0.1617\n",
            "Epoch 227/300\n",
            "67/67 [==============================] - 0s 305us/sample - loss: 0.0345 - mean_squared_error: 0.0345 - mean_absolute_error: 0.1349 - val_loss: 0.0415 - val_mean_squared_error: 0.0415 - val_mean_absolute_error: 0.1622\n",
            "Epoch 228/300\n",
            "67/67 [==============================] - 0s 299us/sample - loss: 0.0347 - mean_squared_error: 0.0347 - mean_absolute_error: 0.1346 - val_loss: 0.0415 - val_mean_squared_error: 0.0415 - val_mean_absolute_error: 0.1603\n",
            "Epoch 229/300\n",
            "67/67 [==============================] - 0s 306us/sample - loss: 0.0339 - mean_squared_error: 0.0339 - mean_absolute_error: 0.1328 - val_loss: 0.0427 - val_mean_squared_error: 0.0427 - val_mean_absolute_error: 0.1574\n",
            "Epoch 230/300\n",
            "67/67 [==============================] - 0s 338us/sample - loss: 0.0353 - mean_squared_error: 0.0353 - mean_absolute_error: 0.1358 - val_loss: 0.0445 - val_mean_squared_error: 0.0445 - val_mean_absolute_error: 0.1567\n",
            "Epoch 231/300\n",
            "67/67 [==============================] - 0s 308us/sample - loss: 0.0358 - mean_squared_error: 0.0358 - mean_absolute_error: 0.1368 - val_loss: 0.0432 - val_mean_squared_error: 0.0432 - val_mean_absolute_error: 0.1566\n",
            "Epoch 232/300\n",
            "67/67 [==============================] - 0s 269us/sample - loss: 0.0348 - mean_squared_error: 0.0348 - mean_absolute_error: 0.1349 - val_loss: 0.0418 - val_mean_squared_error: 0.0418 - val_mean_absolute_error: 0.1577\n",
            "Epoch 233/300\n",
            "67/67 [==============================] - 0s 294us/sample - loss: 0.0340 - mean_squared_error: 0.0340 - mean_absolute_error: 0.1335 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_mean_absolute_error: 0.1598\n",
            "Epoch 234/300\n",
            "67/67 [==============================] - 0s 271us/sample - loss: 0.0342 - mean_squared_error: 0.0342 - mean_absolute_error: 0.1342 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_mean_absolute_error: 0.1606\n",
            "Epoch 235/300\n",
            "67/67 [==============================] - 0s 349us/sample - loss: 0.0343 - mean_squared_error: 0.0343 - mean_absolute_error: 0.1343 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_mean_absolute_error: 0.1594\n",
            "Epoch 236/300\n",
            "67/67 [==============================] - 0s 267us/sample - loss: 0.0344 - mean_squared_error: 0.0344 - mean_absolute_error: 0.1343 - val_loss: 0.0420 - val_mean_squared_error: 0.0420 - val_mean_absolute_error: 0.1568\n",
            "Epoch 237/300\n",
            "67/67 [==============================] - 0s 282us/sample - loss: 0.0344 - mean_squared_error: 0.0344 - mean_absolute_error: 0.1342 - val_loss: 0.0440 - val_mean_squared_error: 0.0440 - val_mean_absolute_error: 0.1557\n",
            "Epoch 238/300\n",
            "67/67 [==============================] - 0s 248us/sample - loss: 0.0360 - mean_squared_error: 0.0360 - mean_absolute_error: 0.1371 - val_loss: 0.0444 - val_mean_squared_error: 0.0444 - val_mean_absolute_error: 0.1558\n",
            "Epoch 239/300\n",
            "67/67 [==============================] - 0s 255us/sample - loss: 0.0356 - mean_squared_error: 0.0356 - mean_absolute_error: 0.1359 - val_loss: 0.0424 - val_mean_squared_error: 0.0424 - val_mean_absolute_error: 0.1566\n",
            "Epoch 240/300\n",
            "67/67 [==============================] - 0s 252us/sample - loss: 0.0344 - mean_squared_error: 0.0344 - mean_absolute_error: 0.1339 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_mean_absolute_error: 0.1585\n",
            "Epoch 241/300\n",
            "67/67 [==============================] - 0s 244us/sample - loss: 0.0340 - mean_squared_error: 0.0340 - mean_absolute_error: 0.1342 - val_loss: 0.0410 - val_mean_squared_error: 0.0410 - val_mean_absolute_error: 0.1609\n",
            "Epoch 242/300\n",
            "67/67 [==============================] - 0s 295us/sample - loss: 0.0344 - mean_squared_error: 0.0344 - mean_absolute_error: 0.1353 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_mean_absolute_error: 0.1623\n",
            "Epoch 243/300\n",
            "67/67 [==============================] - 0s 287us/sample - loss: 0.0348 - mean_squared_error: 0.0348 - mean_absolute_error: 0.1364 - val_loss: 0.0415 - val_mean_squared_error: 0.0415 - val_mean_absolute_error: 0.1641\n",
            "Epoch 244/300\n",
            "67/67 [==============================] - 0s 280us/sample - loss: 0.0355 - mean_squared_error: 0.0355 - mean_absolute_error: 0.1386 - val_loss: 0.0424 - val_mean_squared_error: 0.0424 - val_mean_absolute_error: 0.1664\n",
            "Epoch 245/300\n",
            "67/67 [==============================] - 0s 270us/sample - loss: 0.0366 - mean_squared_error: 0.0366 - mean_absolute_error: 0.1409 - val_loss: 0.0422 - val_mean_squared_error: 0.0422 - val_mean_absolute_error: 0.1652\n",
            "Epoch 246/300\n",
            "67/67 [==============================] - 0s 265us/sample - loss: 0.0355 - mean_squared_error: 0.0355 - mean_absolute_error: 0.1348 - val_loss: 0.0416 - val_mean_squared_error: 0.0416 - val_mean_absolute_error: 0.1592\n",
            "Epoch 247/300\n",
            "67/67 [==============================] - 0s 430us/sample - loss: 0.0344 - mean_squared_error: 0.0344 - mean_absolute_error: 0.1325 - val_loss: 0.0424 - val_mean_squared_error: 0.0424 - val_mean_absolute_error: 0.1579\n",
            "Epoch 248/300\n",
            "67/67 [==============================] - 0s 276us/sample - loss: 0.0355 - mean_squared_error: 0.0355 - mean_absolute_error: 0.1347 - val_loss: 0.0420 - val_mean_squared_error: 0.0420 - val_mean_absolute_error: 0.1602\n",
            "Epoch 249/300\n",
            "67/67 [==============================] - 0s 260us/sample - loss: 0.0347 - mean_squared_error: 0.0347 - mean_absolute_error: 0.1319 - val_loss: 0.0421 - val_mean_squared_error: 0.0421 - val_mean_absolute_error: 0.1593\n",
            "Epoch 250/300\n",
            "67/67 [==============================] - 0s 264us/sample - loss: 0.0345 - mean_squared_error: 0.0345 - mean_absolute_error: 0.1319 - val_loss: 0.0418 - val_mean_squared_error: 0.0418 - val_mean_absolute_error: 0.1580\n",
            "Epoch 251/300\n",
            "67/67 [==============================] - 0s 286us/sample - loss: 0.0339 - mean_squared_error: 0.0339 - mean_absolute_error: 0.1324 - val_loss: 0.0421 - val_mean_squared_error: 0.0421 - val_mean_absolute_error: 0.1568\n",
            "Epoch 252/300\n",
            "67/67 [==============================] - 0s 282us/sample - loss: 0.0342 - mean_squared_error: 0.0342 - mean_absolute_error: 0.1328 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_mean_absolute_error: 0.1602\n",
            "Epoch 253/300\n",
            "67/67 [==============================] - 0s 256us/sample - loss: 0.0356 - mean_squared_error: 0.0356 - mean_absolute_error: 0.1381 - val_loss: 0.0425 - val_mean_squared_error: 0.0425 - val_mean_absolute_error: 0.1669\n",
            "Epoch 254/300\n",
            "67/67 [==============================] - 0s 260us/sample - loss: 0.0364 - mean_squared_error: 0.0364 - mean_absolute_error: 0.1400 - val_loss: 0.0419 - val_mean_squared_error: 0.0419 - val_mean_absolute_error: 0.1644\n",
            "Epoch 255/300\n",
            "67/67 [==============================] - 0s 267us/sample - loss: 0.0356 - mean_squared_error: 0.0356 - mean_absolute_error: 0.1369 - val_loss: 0.0415 - val_mean_squared_error: 0.0415 - val_mean_absolute_error: 0.1619\n",
            "Epoch 256/300\n",
            "67/67 [==============================] - 0s 250us/sample - loss: 0.0342 - mean_squared_error: 0.0342 - mean_absolute_error: 0.1319 - val_loss: 0.0423 - val_mean_squared_error: 0.0423 - val_mean_absolute_error: 0.1570\n",
            "Epoch 257/300\n",
            "67/67 [==============================] - 0s 344us/sample - loss: 0.0342 - mean_squared_error: 0.0342 - mean_absolute_error: 0.1330 - val_loss: 0.0450 - val_mean_squared_error: 0.0450 - val_mean_absolute_error: 0.1573\n",
            "Epoch 258/300\n",
            "67/67 [==============================] - 0s 279us/sample - loss: 0.0371 - mean_squared_error: 0.0371 - mean_absolute_error: 0.1399 - val_loss: 0.0434 - val_mean_squared_error: 0.0434 - val_mean_absolute_error: 0.1565\n",
            "Epoch 259/300\n",
            "67/67 [==============================] - 0s 277us/sample - loss: 0.0347 - mean_squared_error: 0.0347 - mean_absolute_error: 0.1337 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_mean_absolute_error: 0.1613\n",
            "Epoch 260/300\n",
            "67/67 [==============================] - 0s 241us/sample - loss: 0.0354 - mean_squared_error: 0.0354 - mean_absolute_error: 0.1350 - val_loss: 0.0411 - val_mean_squared_error: 0.0411 - val_mean_absolute_error: 0.1619\n",
            "Epoch 261/300\n",
            "67/67 [==============================] - 0s 262us/sample - loss: 0.0334 - mean_squared_error: 0.0334 - mean_absolute_error: 0.1332 - val_loss: 0.0424 - val_mean_squared_error: 0.0424 - val_mean_absolute_error: 0.1557\n",
            "Epoch 262/300\n",
            "67/67 [==============================] - 0s 286us/sample - loss: 0.0350 - mean_squared_error: 0.0350 - mean_absolute_error: 0.1350 - val_loss: 0.0456 - val_mean_squared_error: 0.0456 - val_mean_absolute_error: 0.1542\n",
            "Epoch 263/300\n",
            "67/67 [==============================] - 0s 280us/sample - loss: 0.0368 - mean_squared_error: 0.0368 - mean_absolute_error: 0.1382 - val_loss: 0.0430 - val_mean_squared_error: 0.0430 - val_mean_absolute_error: 0.1541\n",
            "Epoch 264/300\n",
            "67/67 [==============================] - 0s 295us/sample - loss: 0.0348 - mean_squared_error: 0.0348 - mean_absolute_error: 0.1357 - val_loss: 0.0411 - val_mean_squared_error: 0.0411 - val_mean_absolute_error: 0.1586\n",
            "Epoch 265/300\n",
            "67/67 [==============================] - 0s 268us/sample - loss: 0.0345 - mean_squared_error: 0.0345 - mean_absolute_error: 0.1375 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_mean_absolute_error: 0.1624\n",
            "Epoch 266/300\n",
            "67/67 [==============================] - 0s 288us/sample - loss: 0.0348 - mean_squared_error: 0.0348 - mean_absolute_error: 0.1399 - val_loss: 0.0417 - val_mean_squared_error: 0.0417 - val_mean_absolute_error: 0.1651\n",
            "Epoch 267/300\n",
            "67/67 [==============================] - 0s 336us/sample - loss: 0.0358 - mean_squared_error: 0.0358 - mean_absolute_error: 0.1445 - val_loss: 0.0429 - val_mean_squared_error: 0.0429 - val_mean_absolute_error: 0.1692\n",
            "Epoch 268/300\n",
            "67/67 [==============================] - 0s 297us/sample - loss: 0.0370 - mean_squared_error: 0.0370 - mean_absolute_error: 0.1463 - val_loss: 0.0415 - val_mean_squared_error: 0.0415 - val_mean_absolute_error: 0.1635\n",
            "Epoch 269/300\n",
            "67/67 [==============================] - 0s 253us/sample - loss: 0.0343 - mean_squared_error: 0.0343 - mean_absolute_error: 0.1363 - val_loss: 0.0419 - val_mean_squared_error: 0.0419 - val_mean_absolute_error: 0.1555\n",
            "Epoch 270/300\n",
            "67/67 [==============================] - 0s 326us/sample - loss: 0.0345 - mean_squared_error: 0.0345 - mean_absolute_error: 0.1343 - val_loss: 0.0446 - val_mean_squared_error: 0.0446 - val_mean_absolute_error: 0.1548\n",
            "Epoch 271/300\n",
            "67/67 [==============================] - 0s 276us/sample - loss: 0.0366 - mean_squared_error: 0.0366 - mean_absolute_error: 0.1390 - val_loss: 0.0430 - val_mean_squared_error: 0.0430 - val_mean_absolute_error: 0.1547\n",
            "Epoch 272/300\n",
            "67/67 [==============================] - 0s 305us/sample - loss: 0.0357 - mean_squared_error: 0.0357 - mean_absolute_error: 0.1346 - val_loss: 0.0411 - val_mean_squared_error: 0.0411 - val_mean_absolute_error: 0.1589\n",
            "Epoch 273/300\n",
            "67/67 [==============================] - 0s 267us/sample - loss: 0.0340 - mean_squared_error: 0.0340 - mean_absolute_error: 0.1324 - val_loss: 0.0411 - val_mean_squared_error: 0.0411 - val_mean_absolute_error: 0.1578\n",
            "Epoch 274/300\n",
            "67/67 [==============================] - 0s 277us/sample - loss: 0.0338 - mean_squared_error: 0.0338 - mean_absolute_error: 0.1324 - val_loss: 0.0410 - val_mean_squared_error: 0.0410 - val_mean_absolute_error: 0.1574\n",
            "Epoch 275/300\n",
            "67/67 [==============================] - 0s 312us/sample - loss: 0.0337 - mean_squared_error: 0.0337 - mean_absolute_error: 0.1326 - val_loss: 0.0410 - val_mean_squared_error: 0.0410 - val_mean_absolute_error: 0.1575\n",
            "Epoch 276/300\n",
            "67/67 [==============================] - 0s 342us/sample - loss: 0.0338 - mean_squared_error: 0.0338 - mean_absolute_error: 0.1330 - val_loss: 0.0409 - val_mean_squared_error: 0.0409 - val_mean_absolute_error: 0.1577\n",
            "Epoch 277/300\n",
            "67/67 [==============================] - 0s 252us/sample - loss: 0.0338 - mean_squared_error: 0.0338 - mean_absolute_error: 0.1326 - val_loss: 0.0408 - val_mean_squared_error: 0.0408 - val_mean_absolute_error: 0.1591\n",
            "Epoch 278/300\n",
            "67/67 [==============================] - 0s 278us/sample - loss: 0.0345 - mean_squared_error: 0.0345 - mean_absolute_error: 0.1332 - val_loss: 0.0415 - val_mean_squared_error: 0.0415 - val_mean_absolute_error: 0.1627\n",
            "Epoch 279/300\n",
            "67/67 [==============================] - 0s 344us/sample - loss: 0.0354 - mean_squared_error: 0.0354 - mean_absolute_error: 0.1352 - val_loss: 0.0416 - val_mean_squared_error: 0.0416 - val_mean_absolute_error: 0.1627\n",
            "Epoch 280/300\n",
            "67/67 [==============================] - 0s 279us/sample - loss: 0.0349 - mean_squared_error: 0.0349 - mean_absolute_error: 0.1341 - val_loss: 0.0411 - val_mean_squared_error: 0.0411 - val_mean_absolute_error: 0.1571\n",
            "Epoch 281/300\n",
            "67/67 [==============================] - 0s 254us/sample - loss: 0.0345 - mean_squared_error: 0.0345 - mean_absolute_error: 0.1344 - val_loss: 0.0447 - val_mean_squared_error: 0.0447 - val_mean_absolute_error: 0.1544\n",
            "Epoch 282/300\n",
            "67/67 [==============================] - 0s 273us/sample - loss: 0.0368 - mean_squared_error: 0.0368 - mean_absolute_error: 0.1394 - val_loss: 0.0449 - val_mean_squared_error: 0.0449 - val_mean_absolute_error: 0.1538\n",
            "Epoch 283/300\n",
            "67/67 [==============================] - 0s 347us/sample - loss: 0.0360 - mean_squared_error: 0.0360 - mean_absolute_error: 0.1374 - val_loss: 0.0415 - val_mean_squared_error: 0.0415 - val_mean_absolute_error: 0.1543\n",
            "Epoch 284/300\n",
            "67/67 [==============================] - 0s 282us/sample - loss: 0.0337 - mean_squared_error: 0.0337 - mean_absolute_error: 0.1329 - val_loss: 0.0405 - val_mean_squared_error: 0.0405 - val_mean_absolute_error: 0.1597\n",
            "Epoch 285/300\n",
            "67/67 [==============================] - 0s 256us/sample - loss: 0.0342 - mean_squared_error: 0.0342 - mean_absolute_error: 0.1355 - val_loss: 0.0405 - val_mean_squared_error: 0.0405 - val_mean_absolute_error: 0.1596\n",
            "Epoch 286/300\n",
            "67/67 [==============================] - 0s 268us/sample - loss: 0.0334 - mean_squared_error: 0.0334 - mean_absolute_error: 0.1331 - val_loss: 0.0417 - val_mean_squared_error: 0.0417 - val_mean_absolute_error: 0.1540\n",
            "Epoch 287/300\n",
            "67/67 [==============================] - 0s 292us/sample - loss: 0.0353 - mean_squared_error: 0.0353 - mean_absolute_error: 0.1364 - val_loss: 0.0443 - val_mean_squared_error: 0.0443 - val_mean_absolute_error: 0.1521\n",
            "Epoch 288/300\n",
            "67/67 [==============================] - 0s 337us/sample - loss: 0.0364 - mean_squared_error: 0.0364 - mean_absolute_error: 0.1368 - val_loss: 0.0418 - val_mean_squared_error: 0.0418 - val_mean_absolute_error: 0.1551\n",
            "Epoch 289/300\n",
            "67/67 [==============================] - 0s 261us/sample - loss: 0.0342 - mean_squared_error: 0.0342 - mean_absolute_error: 0.1339 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_mean_absolute_error: 0.1641\n",
            "Epoch 290/300\n",
            "67/67 [==============================] - 0s 247us/sample - loss: 0.0363 - mean_squared_error: 0.0363 - mean_absolute_error: 0.1444 - val_loss: 0.0412 - val_mean_squared_error: 0.0412 - val_mean_absolute_error: 0.1642\n",
            "Epoch 291/300\n",
            "67/67 [==============================] - 0s 354us/sample - loss: 0.0346 - mean_squared_error: 0.0346 - mean_absolute_error: 0.1391 - val_loss: 0.0423 - val_mean_squared_error: 0.0423 - val_mean_absolute_error: 0.1536\n",
            "Epoch 292/300\n",
            "67/67 [==============================] - 0s 282us/sample - loss: 0.0342 - mean_squared_error: 0.0342 - mean_absolute_error: 0.1325 - val_loss: 0.0503 - val_mean_squared_error: 0.0503 - val_mean_absolute_error: 0.1544\n",
            "Epoch 293/300\n",
            "67/67 [==============================] - 0s 262us/sample - loss: 0.0416 - mean_squared_error: 0.0416 - mean_absolute_error: 0.1491 - val_loss: 0.0538 - val_mean_squared_error: 0.0538 - val_mean_absolute_error: 0.1577\n",
            "Epoch 294/300\n",
            "67/67 [==============================] - 0s 248us/sample - loss: 0.0451 - mean_squared_error: 0.0451 - mean_absolute_error: 0.1548 - val_loss: 0.0492 - val_mean_squared_error: 0.0492 - val_mean_absolute_error: 0.1519\n",
            "Epoch 295/300\n",
            "67/67 [==============================] - 0s 268us/sample - loss: 0.0382 - mean_squared_error: 0.0382 - mean_absolute_error: 0.1389 - val_loss: 0.0410 - val_mean_squared_error: 0.0410 - val_mean_absolute_error: 0.1594\n",
            "Epoch 296/300\n",
            "67/67 [==============================] - 0s 270us/sample - loss: 0.0352 - mean_squared_error: 0.0352 - mean_absolute_error: 0.1397 - val_loss: 0.0470 - val_mean_squared_error: 0.0470 - val_mean_absolute_error: 0.1790\n",
            "Epoch 297/300\n",
            "67/67 [==============================] - 0s 284us/sample - loss: 0.0427 - mean_squared_error: 0.0427 - mean_absolute_error: 0.1615 - val_loss: 0.0466 - val_mean_squared_error: 0.0466 - val_mean_absolute_error: 0.1761\n",
            "Epoch 298/300\n",
            "67/67 [==============================] - 0s 276us/sample - loss: 0.0411 - mean_squared_error: 0.0411 - mean_absolute_error: 0.1559 - val_loss: 0.0410 - val_mean_squared_error: 0.0410 - val_mean_absolute_error: 0.1633\n",
            "Epoch 299/300\n",
            "67/67 [==============================] - 0s 253us/sample - loss: 0.0341 - mean_squared_error: 0.0341 - mean_absolute_error: 0.1346 - val_loss: 0.0419 - val_mean_squared_error: 0.0419 - val_mean_absolute_error: 0.1562\n",
            "Epoch 300/300\n",
            "67/67 [==============================] - 0s 252us/sample - loss: 0.0349 - mean_squared_error: 0.0349 - mean_absolute_error: 0.1350 - val_loss: 0.0490 - val_mean_squared_error: 0.0490 - val_mean_absolute_error: 0.1583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5aNfodbA8xs",
        "colab_type": "code",
        "outputId": "72f5a6b2-2d6c-489a-9850-5b465b969b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 0s 298us/sample - loss: 0.0385 - mean_squared_error: 0.0385 - mean_absolute_error: 0.1596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03854225850418994, 0.03854226, 0.15955734]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vSB68BWBCFk",
        "colab_type": "code",
        "outputId": "8b267856-e390-4495-eec8-519cf49df364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "y_pred = model.predict_classes(X_test[0:3])\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgT_AsS6Bhum",
        "colab_type": "code",
        "outputId": "bf6fab31-9c45-4d22-da6d-8c85a2d689e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "y_pred,y_test[0:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1],\n",
              "        [0],\n",
              "        [1]], dtype=int32), 123    1.8\n",
              " 19     0.3\n",
              " 128    2.1\n",
              " Name: 3, dtype: float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DywDmLzTCgof",
        "colab_type": "code",
        "outputId": "9cb19307-c0f6-48ad-82eb-51434b1ae157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training','Testing'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAxTUhARkWFKCiIiMuz/A+cUpaGuwaaXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7WD7TnbD2d9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}